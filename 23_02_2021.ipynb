{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"23_02_2021.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkd9R9agOUZAvu1DbZ6Alf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9WgItDsJfVz","executionInfo":{"status":"ok","timestamp":1614054631777,"user_tz":-330,"elapsed":17148,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"56d9917a-c835-4c81-e787-b4a371f17756"},"source":["!git clone https://github.com/Adamouization/Content-Based-Video-Retrieval-Code.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'Content-Based-Video-Retrieval-Code'...\n","remote: Enumerating objects: 908, done.\u001b[K\n","remote: Total 908 (delta 0), reused 0 (delta 0), pack-reused 908\u001b[K\n","Receiving objects: 100% (908/908), 418.20 MiB | 30.51 MiB/s, done.\n","Resolving deltas: 100% (400/400), done.\n","Checking out files: 100% (247/247), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8KTeEKZJ0dV","executionInfo":{"status":"ok","timestamp":1614054863867,"user_tz":-330,"elapsed":2249,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"d81d1acd-2355-41f5-df3b-f0b08e2e5ddc"},"source":["%cd /content/Content-Based-Video-Retrieval-Code"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/Content-Based-Video-Retrieval-Code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hEXXCJ8CJ59h","executionInfo":{"status":"ok","timestamp":1614054764981,"user_tz":-330,"elapsed":61951,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"5072d0d3-e24c-488b-a622-80f596f17e8b"},"source":["!pip install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting appnope==0.1.0\n","  Downloading https://files.pythonhosted.org/packages/87/a9/7985e6a53402f294c8f0e8eff3151a83f1fb901fa92909bb3ff29b4d22af/appnope-0.1.0-py2.py3-none-any.whl\n","Collecting backcall==0.1.0\n","  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.10.0)\n","Collecting decorator==4.3.2\n","  Downloading https://files.pythonhosted.org/packages/f1/cd/7c8240007e9716b14679bc217a1baefa4432aa30394f7e2ec40a52b1a708/decorator-4.3.2-py2.py3-none-any.whl\n","Collecting futures==3.1.1\n","  Downloading https://files.pythonhosted.org/packages/05/80/f41cca0ea1ff69bce7e7a7d76182b47bb4e1a494380a532af3e8ee70b9ec/futures-3.1.1-py3-none-any.whl\n","Collecting imutils==0.5.2\n","  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\n","Collecting ipython==7.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/b4/a9ea018c73a84ee6280b2e94a1a6af8d63e45903eac2da0640fa63bca4db/ipython-7.2.0-py3-none-any.whl (765kB)\n","\u001b[K     |████████████████████████████████| 768kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n","Collecting jedi==0.13.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/bc/54d53f5bc4658380d0eca9055d72be4df45e5bfd91a4bac97da224a92553/jedi-0.13.2-py2.py3-none-any.whl (177kB)\n","\u001b[K     |████████████████████████████████| 184kB 10.2MB/s \n","\u001b[?25hCollecting kiwisolver==1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n","\u001b[K     |████████████████████████████████| 952kB 12.6MB/s \n","\u001b[?25hCollecting matplotlib==3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n","\u001b[K     |████████████████████████████████| 12.9MB 329kB/s \n","\u001b[?25hCollecting numpy==1.16.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 250kB/s \n","\u001b[?25hCollecting opencv-contrib-python==4.0.0.21\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/c0/0463d91f297521b2e15e3d682d7077557fe773db72a03a0d2dba899ab8a5/opencv_contrib_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 139kB/s \n","\u001b[?25hCollecting opencv-python==4.0.0.21\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n","\u001b[K     |████████████████████████████████| 25.4MB 107kB/s \n","\u001b[?25hCollecting pandas==0.24.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n","\u001b[K     |████████████████████████████████| 10.1MB 40.0MB/s \n","Collecting scipy==1.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n","\u001b[K     |████████████████████████████████| 24.8MB 1.6MB/s \n","\u001b[?25hCollecting six==1.12.0\n","  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n","Collecting terminaltables==3.1.0\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting traitlets==4.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 8.0MB/s \n","\u001b[?25hCollecting vidstab==1.5.6\n","  Downloading https://files.pythonhosted.org/packages/df/92/d0509c08df448cd22b137557d8c63e4b75aa3e688b3dc0d2a7cfd9a1ec17/vidstab-1.5.6-py2.py3-none-any.whl\n","Collecting wcwidth==0.1.7\n","  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.2.0->-r requirements.txt (line 7)) (53.0.0)\n","Building wheels for collected packages: backcall, imutils, progress, terminaltables\n","  Building wheel for backcall (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for backcall: filename=backcall-0.1.0-cp36-none-any.whl size=10414 sha256=80a5a8be267fcbf2688c8542453277bcc1184b13b2fed7693bbc8e1ab74d8f9e\n","  Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45\n","  Building wheel for imutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imutils: filename=imutils-0.5.2-cp36-none-any.whl size=24417 sha256=58287c6b295f03b745a8249d84825bf542a0187479cf5840db27f6e36d33e4ff\n","  Stored in directory: /root/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\n","  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progress: filename=progress-1.4-cp36-none-any.whl size=8832 sha256=ee9c2643cb68fbe70f9120739b2656ab4abdb75635f514dc61efd20c90771ef5\n","  Stored in directory: /root/.cache/pip/wheels/64/a0/ed/3dc6fa129019a02240d84d3e60c7b1a8767fcf0fe340fac9d6\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=d407c59ced93487ae82df58ce3c019ad12b4de14ac5f680ac4d8b247c9268e71\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built backcall imutils progress terminaltables\n","\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: umap-learn 0.5.0 has requirement numpy>=1.17, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.2 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jupyterlab-pygments 0.1.2 has requirement pygments<3,>=2.4.1, but you'll have pygments 2.3.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.8 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement python-dateutil>=2.8.0, but you'll have python-dateutil 2.7.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: appnope, backcall, decorator, futures, imutils, six, traitlets, ptyprocess, pexpect, wcwidth, prompt-toolkit, parso, jedi, Pygments, ipython, kiwisolver, python-dateutil, pyparsing, numpy, matplotlib, opencv-contrib-python, opencv-python, pandas, progress, pyspin, python-utils, scipy, terminaltables, vidstab\n","  Found existing installation: backcall 0.2.0\n","    Uninstalling backcall-0.2.0:\n","      Successfully uninstalled backcall-0.2.0\n","  Found existing installation: decorator 4.4.2\n","    Uninstalling decorator-4.4.2:\n","      Successfully uninstalled decorator-4.4.2\n","  Found existing installation: imutils 0.5.4\n","    Uninstalling imutils-0.5.4:\n","      Successfully uninstalled imutils-0.5.4\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: traitlets 4.3.3\n","    Uninstalling traitlets-4.3.3:\n","      Successfully uninstalled traitlets-4.3.3\n","  Found existing installation: ptyprocess 0.7.0\n","    Uninstalling ptyprocess-0.7.0:\n","      Successfully uninstalled ptyprocess-0.7.0\n","  Found existing installation: pexpect 4.8.0\n","    Uninstalling pexpect-4.8.0:\n","      Successfully uninstalled pexpect-4.8.0\n","  Found existing installation: wcwidth 0.2.5\n","    Uninstalling wcwidth-0.2.5:\n","      Successfully uninstalled wcwidth-0.2.5\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: parso 0.8.1\n","    Uninstalling parso-0.8.1:\n","      Successfully uninstalled parso-0.8.1\n","  Found existing installation: jedi 0.18.0\n","    Uninstalling jedi-0.18.0:\n","      Successfully uninstalled jedi-0.18.0\n","  Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Found existing installation: kiwisolver 1.3.1\n","    Uninstalling kiwisolver-1.3.1:\n","      Successfully uninstalled kiwisolver-1.3.1\n","  Found existing installation: python-dateutil 2.8.1\n","    Uninstalling python-dateutil-2.8.1:\n","      Successfully uninstalled python-dateutil-2.8.1\n","  Found existing installation: pyparsing 2.4.7\n","    Uninstalling pyparsing-2.4.7:\n","      Successfully uninstalled pyparsing-2.4.7\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","  Found existing installation: python-utils 2.5.6\n","    Uninstalling python-utils-2.5.6:\n","      Successfully uninstalled python-utils-2.5.6\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","Successfully installed Pygments-2.3.1 appnope-0.1.0 backcall-0.1.0 decorator-4.3.2 futures-3.1.1 imutils-0.5.2 ipython-7.2.0 jedi-0.13.2 kiwisolver-1.0.1 matplotlib-3.0.2 numpy-1.16.0 opencv-contrib-python-4.0.0.21 opencv-python-4.0.0.21 pandas-0.24.1 parso-0.3.2 pexpect-4.6.0 progress-1.4 prompt-toolkit-2.0.8 ptyprocess-0.6.0 pyparsing-2.3.1 pyspin-1.1.1 python-dateutil-2.7.5 python-utils-2.3.0 scipy-1.2.1 six-1.12.0 terminaltables-3.1.0 traitlets-4.3.2 vidstab-1.5.6 wcwidth-0.1.7\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","dateutil","decorator","kiwisolver","matplotlib","mpl_toolkits","numpy","pandas","pexpect","prompt_toolkit","pygments","pyparsing","six","traitlets","wcwidth"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIrX1psHKmiZ","executionInfo":{"status":"ok","timestamp":1614055670669,"user_tz":-330,"elapsed":1188,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"8cd4754d-e955-48bd-f4f5-51ec68a0fa1e"},"source":["!ls"],"execution_count":7,"outputs":[{"output_type":"stream","text":["app  footage  LICENSE  README.md  recordings  requirements.txt\tresults\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S3z-VBofNwzg","executionInfo":{"status":"ok","timestamp":1614056340446,"user_tz":-330,"elapsed":3276,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}}},"source":["import app.config as config\r\n","#from app.helpers import display_results_histogram, get_number_of_frames, get_video_filenames, get_video_fps, \\\r\n","    #get_video_first_frame, print_finished_training_message, terminal_yes_no_question, show_final_match, \\\r\n","    #video_file_already_stabilised\r\n","from app.helpers import display_results_histogram\r\n","from app.helpers import get_number_of_frames\r\n","from app.helpers import get_video_filenames\r\n","from app.helpers import get_video_fps\r\n","from app.helpers import get_video_first_frame\r\n","from app.helpers import  print_finished_training_message\r\n","from app.helpers import terminal_yes_no_question\r\n","from app.helpers import show_final_match\r\n","from app.helpers import video_file_already_stabilised\r\n","    #get_video_first_frame, print_finished_training_message, terminal_yes_no_question, show_final_match, \\\r\n","    #video_file_already_stabilised\r\n","from app.histogram import HistogramGenerator\r\n","from app.video_operations import VideoStabiliser\r\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQvoUDq6Kta7","executionInfo":{"status":"ok","timestamp":1614056454522,"user_tz":-330,"elapsed":3042,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"84f630e5-ba6d-460f-c24a-7d9b00505cd7"},"source":["!python /content/Content-Based-Video-Retrieval-Code/app/main.py --model all --mode test"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/content/Content-Based-Video-Retrieval-Code/app/main.py\", line 11, in <module>\n","    from app.helpers import display_results_histogram\n","ModuleNotFoundError: No module named 'app'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yM_4zyQPLVSX"},"source":["import argparse\r\n","from collections import Counter\r\n","import time\r\n","\r\n","from pyspin.spin import make_spin, Spin2\r\n","\r\n","import app.config as config\r\n","from app.helpers import display_results_histogram, get_number_of_frames, get_video_filenames, get_video_fps, \\\r\n","    get_video_first_frame, print_finished_training_message, terminal_yes_no_question, show_final_match, \\\r\n","    video_file_already_stabilised\r\n","from app.histogram import HistogramGenerator\r\n","from app.video_operations import VideoStabiliser\r\n","\r\n","\r\n","def main():\r\n","    \"\"\"\r\n","    Program entry point. Parses command line input to decide which phase of the system to run.\r\n","    :return: None\r\n","    \"\"\"\r\n","    parser = argparse.ArgumentParser()\r\n","    parser.add_argument(\"-m\", \"--model\",\r\n","                        help=\"The histogram model to use. Choose from the following options: 'rgb', 'hsv' or 'gray'. \"\r\n","                             \"Leave empty to train using all 3 histogram models.\")\r\n","    parser.add_argument(\"--mode\",\r\n","                        required=True,\r\n","                        help=\"The mode to run the code in. Choose from the following options: 'train', 'test' or \"\r\n","                             \"'segment'.\")\r\n","    parser.add_argument(\"--showhists\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to display each generated histogram.\")\r\n","    parser.add_argument(\"-d\", \"--debug\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to print additional logs for debugging purposes.\")\r\n","    args = parser.parse_args()\r\n","    config.debug = args.debug\r\n","    config.mode = args.mode\r\n","    config.show_histograms = args.showhists\r\n","    config.model = args.model\r\n","\r\n","    if config.mode == \"train\":\r\n","        off_line_colour_based_feature_extraction_phase()\r\n","    elif config.mode == \"test\":\r\n","        on_line_retrieval_phase()\r\n","    elif config.mode == \"segment\":\r\n","        database_preprocessing_phase()\r\n","    else:\r\n","        print(\"Wrong mode chosen. Choose from the following options: 'train', 'test' or 'segment'.\")\r\n","        exit(0)\r\n","\r\n","\r\n","@make_spin(Spin2, \"Generating histograms for database videos...\".format(config.model))\r\n","def off_line_colour_based_feature_extraction_phase():\r\n","    \"\"\"\r\n","    Generates and stores averaged greyscale, RGB and HSV histograms for all the videos in the directory-based database.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"../footage/\"\r\n","    files = get_video_filenames(directory)\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    for file in files:\r\n","        if config.model == \"gray\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_greyscale_histogram()\r\n","        elif config.model == \"rgb\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_rgb_histogram()\r\n","        elif config.model == \"hsv\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_hsv_histogram()\r\n","        else:\r\n","            histogram_generator_gray = HistogramGenerator(directory, file)\r\n","            histogram_generator_gray.generate_video_greyscale_histogram()\r\n","            histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","            histogram_generator_rgb.generate_video_rgb_histogram()\r\n","            histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","            histogram_generator_hsv.generate_video_hsv_histogram()\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print_finished_training_message(config.model, directory, runtime)\r\n","\r\n","\r\n","def on_line_retrieval_phase():\r\n","    \"\"\"\r\n","    Prompts the user to stabilise and crop the query video before generating the same averaged greyscale, RGB and HSV\r\n","    histograms to compare with the database videos' previously stored histograms using distance metrics.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"../recordings/\"\r\n","    recordings = [\"recording1.mp4\", \"recording2.mp4\", \"recording3.mp4\", \"recording4.mp4\", \"recording5.mp4\",\r\n","                  \"recording6.mp4\", \"recording7.mp4\", \"recording8.mp4\"]\r\n","    mismatches_directory = \"../recordings/mismatches/\"\r\n","    mismatches = [\"mismatch1.mp4\", \"mismatch2.mp4\"]\r\n","    # 0: cloudy-sky, 1: seal, 2: butterfly (skewed), 3: wind-turbine, 4: ice-hockey, 5: jellyfish, 6: people-dancing,\r\n","    # 7: jellyfish (skewed)\r\n","    file = recordings[7]\r\n","\r\n","    # ask user to stabilise the input query video or not\r\n","    is_stabilise_video = terminal_yes_no_question(\"Do you wish to stabilise the recorded query video?\")\r\n","    stable_filename = \"stable-\" + file[:-4] + \".avi\"  # the stable version of the video\r\n","    # yes: stabilise the video and use the stable .avi version\r\n","    if is_stabilise_video:\r\n","        if not video_file_already_stabilised(directory + stable_filename):\r\n","            VideoStabiliser(directory, \"{}\".format(file))\r\n","        print(\"\\nStabilised version of query already found: '{}'\".format(stable_filename))\r\n","        file = stable_filename\r\n","    # no: check if a version of the stabilised video doesn't already exist - use it if it does\r\n","    else:\r\n","        if video_file_already_stabilised(directory + stable_filename):\r\n","            file = stable_filename\r\n","\r\n","    print(\"\\nUsing query: '{}'\".format(file))\r\n","    print(\"\\nPlease crop the recorded query video for the signature to be generated.\")\r\n","\r\n","    if config.model == \"gray\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_greyscale_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"rgb\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_rgb_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"hsv\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_hsv_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    else:\r\n","        # calculate query histogram\r\n","        # greyscale\r\n","        histogram_generator_gray = HistogramGenerator(directory, file)\r\n","        histogram_generator_gray.generate_video_greyscale_histogram(is_query=True)\r\n","        cur_reference_points = histogram_generator_gray.get_current_reference_points()\r\n","        # start measuring runtime (after manual cropping)\r\n","        start_time = time.time()\r\n","        # RGB\r\n","        histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","        histogram_generator_rgb.generate_video_rgb_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","        # HSV\r\n","        histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","        histogram_generator_hsv.generate_video_hsv_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","\r\n","        # calculate distances between query and DB histograms\r\n","        histogram_generator_gray.match_histograms(cur_all_model='gray')\r\n","        histogram_generator_rgb.match_histograms(cur_all_model='rgb')\r\n","        histogram_generator_hsv.match_histograms(cur_all_model='hsv')\r\n","\r\n","        # Combine matches from all 3 histogram models to output one final result\r\n","        all_results = histogram_generator_hsv.get_results_array()  # array of all matches made (using weights)\r\n","        results_count = Counter(all_results)  # count the number of matches made for each video in all_results array\r\n","        # transform from count to percentage of matches made\r\n","        results_percentage = dict()\r\n","        for match in results_count:\r\n","            percentage = round((results_count[match] / len(all_results)) * 100.0, 2)\r\n","            results_percentage[match] = percentage\r\n","        display_results_histogram(results_percentage)\r\n","        print(\"Matches made: {}\".format(results_count))\r\n","        print(\"% of matches made: {}\".format(results_percentage))\r\n","\r\n","        # find best result\r\n","        final_result_name = \"\"\r\n","        final_result_count = 0\r\n","        for i, r in enumerate(results_count):\r\n","            if i == 0:\r\n","                final_result_name = r\r\n","                final_result_count = results_count[r]\r\n","            else:\r\n","                if results_count[r] > final_result_count:\r\n","                    final_result_name = r\r\n","                    final_result_count = results_count[r]\r\n","\r\n","        # print results\r\n","        runtime = round(time.time() - start_time, 2)\r\n","        accuracy = final_result_count / len(all_results)\r\n","        get_video_first_frame(directory + file, \"../results\", is_query=True)\r\n","        get_video_first_frame(\"../footage/{}\".format(final_result_name), \"../results\", is_result=True)\r\n","        show_final_match(final_result_name, \"../results/query.png\", \"../results/result.png\", runtime, accuracy)\r\n","        print_finished_training_message(final_result_name, config.model, runtime, accuracy)\r\n","\r\n","\r\n","def database_preprocessing_phase():\r\n","    \"\"\"\r\n","    Applies a shot boundary detection algorithm to a video for segmentation.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"../recordings/\"\r\n","    video = \"scene-segmentation.mp4\"\r\n","    # directory = \"/Volumes/ADAM2/\"\r\n","    # movies = [\"Inception (2010).mp4\"]\r\n","    # video = movies[0]\r\n","\r\n","    shot_boundary_detector = HistogramGenerator(directory, video)\r\n","    video_capture = shot_boundary_detector.get_video_capture()\r\n","    frame_count = get_number_of_frames(vc=video_capture)\r\n","    fps = get_video_fps(vc=video_capture)\r\n","    print(\"Total Frames: {}\".format(frame_count))\r\n","    print(\"FPS: {}\\n\".format(fps))\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    # start processing video for shout boundary detection\r\n","    print(\"Starting to process video for shot boundary detection...\")\r\n","    shot_boundary_detector.rgb_histogram_shot_boundary_detection(threshold=7)\r\n","\r\n","    # print final results\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print(\"--- Number of frames in video: {} ---\".format(frame_count))\r\n","    print(\"--- Runtime: {} seconds ---\".format(runtime))\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VLSVpG3OMR32"},"source":["import argparse\r\n","from collections import Counter\r\n","import time\r\n","\r\n","from pyspin.spin import make_spin, Spin2\r\n","\r\n","import config as config\r\n","from helpers import display_results_histogram, get_number_of_frames, get_video_filenames, get_video_fps, \\\r\n","    get_video_first_frame, print_finished_training_message, terminal_yes_no_question, show_final_match, \\\r\n","    video_file_already_stabilised\r\n","from histogram import HistogramGenerator\r\n","from video_operations import VideoStabiliser\r\n","\r\n","\r\n","def main():\r\n","    \"\"\"\r\n","    Program entry point. Parses command line input to decide which phase of the system to run.\r\n","    :return: None\r\n","    \"\"\"\r\n","    parser = argparse.ArgumentParser()\r\n","    parser.add_argument(\"-m\", \"--model\",\r\n","                        help=\"The histogram model to use. Choose from the following options: 'rgb', 'hsv' or 'gray'. \"\r\n","                             \"Leave empty to train using all 3 histogram models.\")\r\n","    parser.add_argument(\"--mode\",\r\n","                        required=True,\r\n","                        help=\"The mode to run the code in. Choose from the following options: 'train', 'test' or \"\r\n","                             \"'segment'.\")\r\n","    parser.add_argument(\"--showhists\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to display each generated histogram.\")\r\n","    parser.add_argument(\"-d\", \"--debug\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to print additional logs for debugging purposes.\")\r\n","    args = parser.parse_args()\r\n","    config.debug = args.debug\r\n","    config.mode = args.mode\r\n","    config.show_histograms = args.showhists\r\n","    config.model = args.model\r\n","\r\n","    if config.mode == \"train\":\r\n","        off_line_colour_based_feature_extraction_phase()\r\n","    elif config.mode == \"test\":\r\n","        on_line_retrieval_phase()\r\n","    elif config.mode == \"segment\":\r\n","        database_preprocessing_phase()\r\n","    else:\r\n","        print(\"Wrong mode chosen. Choose from the following options: 'train', 'test' or 'segment'.\")\r\n","        exit(0)\r\n","\r\n","\r\n","@make_spin(Spin2, \"Generating histograms for database videos...\".format(config.model))\r\n","def off_line_colour_based_feature_extraction_phase():\r\n","    \"\"\"\r\n","    Generates and stores averaged greyscale, RGB and HSV histograms for all the videos in the directory-based database.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/footage/\"\r\n","    files = get_video_filenames(directory)\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    for file in files:\r\n","        if config.model == \"gray\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_greyscale_histogram()\r\n","        elif config.model == \"rgb\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_rgb_histogram()\r\n","        elif config.model == \"hsv\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_hsv_histogram()\r\n","        else:\r\n","            histogram_generator_gray = HistogramGenerator(directory, file)\r\n","            histogram_generator_gray.generate_video_greyscale_histogram()\r\n","            histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","            histogram_generator_rgb.generate_video_rgb_histogram()\r\n","            histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","            histogram_generator_hsv.generate_video_hsv_histogram()\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print_finished_training_message(config.model, directory, runtime)\r\n","\r\n","\r\n","def on_line_retrieval_phase():\r\n","    \"\"\"\r\n","    Prompts the user to stabilise and crop the query video before generating the same averaged greyscale, RGB and HSV\r\n","    histograms to compare with the database videos' previously stored histograms using distance metrics.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/\"\r\n","    recordings = [\"recording1.mp4\", \"recording2.mp4\", \"recording3.mp4\", \"recording4.mp4\", \"recording5.mp4\",\r\n","                  \"recording6.mp4\", \"recording7.mp4\", \"recording8.mp4\"]\r\n","    mismatches_directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/mismatches/\"\r\n","    mismatches = [\"mismatch1.mp4\", \"mismatch2.mp4\"]\r\n","    # 0: cloudy-sky, 1: seal, 2: butterfly (skewed), 3: wind-turbine, 4: ice-hockey, 5: jellyfish, 6: people-dancing,\r\n","    # 7: jellyfish (skewed)\r\n","    file = recordings[7]\r\n","\r\n","    # ask user to stabilise the input query video or not\r\n","    is_stabilise_video = terminal_yes_no_question(\"Do you wish to stabilise the recorded query video?\")\r\n","    stable_filename = \"stable-\" + file[:-4] + \".avi\"  # the stable version of the video\r\n","    # yes: stabilise the video and use the stable .avi version\r\n","    if is_stabilise_video:\r\n","        if not video_file_already_stabilised(directory + stable_filename):\r\n","            VideoStabiliser(directory, \"{}\".format(file))\r\n","        print(\"\\nStabilised version of query already found: '{}'\".format(stable_filename))\r\n","        file = stable_filename\r\n","    # no: check if a version of the stabilised video doesn't already exist - use it if it does\r\n","    else:\r\n","        if video_file_already_stabilised(directory + stable_filename):\r\n","            file = stable_filename\r\n","\r\n","    print(\"\\nUsing query: '{}'\".format(file))\r\n","    print(\"\\nPlease crop the recorded query video for the signature to be generated.\")\r\n","\r\n","    if config.model == \"gray\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_greyscale_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"rgb\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_rgb_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"hsv\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_hsv_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    else:\r\n","        # calculate query histogram\r\n","        # greyscale\r\n","        histogram_generator_gray = HistogramGenerator(directory, file)\r\n","        histogram_generator_gray.generate_video_greyscale_histogram(is_query=True)\r\n","        cur_reference_points = histogram_generator_gray.get_current_reference_points()\r\n","        # start measuring runtime (after manual cropping)\r\n","        start_time = time.time()\r\n","        # RGB\r\n","        histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","        histogram_generator_rgb.generate_video_rgb_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","        # HSV\r\n","        histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","        histogram_generator_hsv.generate_video_hsv_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","\r\n","        # calculate distances between query and DB histograms\r\n","        histogram_generator_gray.match_histograms(cur_all_model='gray')\r\n","        histogram_generator_rgb.match_histograms(cur_all_model='rgb')\r\n","        histogram_generator_hsv.match_histograms(cur_all_model='hsv')\r\n","\r\n","        # Combine matches from all 3 histogram models to output one final result\r\n","        all_results = histogram_generator_hsv.get_results_array()  # array of all matches made (using weights)\r\n","        results_count = Counter(all_results)  # count the number of matches made for each video in all_results array\r\n","        # transform from count to percentage of matches made\r\n","        results_percentage = dict()\r\n","        for match in results_count:\r\n","            percentage = round((results_count[match] / len(all_results)) * 100.0, 2)\r\n","            results_percentage[match] = percentage\r\n","        display_results_histogram(results_percentage)\r\n","        print(\"Matches made: {}\".format(results_count))\r\n","        print(\"% of matches made: {}\".format(results_percentage))\r\n","\r\n","        # find best result\r\n","        final_result_name = \"\"\r\n","        final_result_count = 0\r\n","        for i, r in enumerate(results_count):\r\n","            if i == 0:\r\n","                final_result_name = r\r\n","                final_result_count = results_count[r]\r\n","            else:\r\n","                if results_count[r] > final_result_count:\r\n","                    final_result_name = r\r\n","                    final_result_count = results_count[r]\r\n","\r\n","        # print results\r\n","        runtime = round(time.time() - start_time, 2)\r\n","        accuracy = final_result_count / len(all_results)\r\n","        get_video_first_frame(directory + file, \"/content/Content-Based-Video-Retrieval-Code/results\", is_query=True)\r\n","        get_video_first_frame(\"/content/Content-Based-Video-Retrieval-Code/footage/{}\".format(final_result_name), \"../results\", is_result=True)\r\n","        show_final_match(final_result_name, \"/content/Content-Based-Video-Retrieval-Code/results/query.png\", \"/content/Content-Based-Video-Retrieval-Code/results/result.png\", runtime, accuracy)\r\n","        print_finished_training_message(final_result_name, config.model, runtime, accuracy)\r\n","\r\n","\r\n","def database_preprocessing_phase():\r\n","    \"\"\"\r\n","    Applies a shot boundary detection algorithm to a video for segmentation.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/\"\r\n","    video = \"scene-segmentation.mp4\"\r\n","    # directory = \"/Volumes/ADAM2/\"\r\n","    # movies = [\"Inception (2010).mp4\"]\r\n","    # video = movies[0]\r\n","\r\n","    shot_boundary_detector = HistogramGenerator(directory, video)\r\n","    video_capture = shot_boundary_detector.get_video_capture()\r\n","    frame_count = get_number_of_frames(vc=video_capture)\r\n","    fps = get_video_fps(vc=video_capture)\r\n","    print(\"Total Frames: {}\".format(frame_count))\r\n","    print(\"FPS: {}\\n\".format(fps))\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    # start processing video for shout boundary detection\r\n","    print(\"Starting to process video for shot boundary detection...\")\r\n","    shot_boundary_detector.rgb_histogram_shot_boundary_detection(threshold=7)\r\n","\r\n","    # print final results\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print(\"--- Number of frames in video: {} ---\".format(frame_count))\r\n","    print(\"--- Runtime: {} seconds ---\".format(runtime))\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Oj0eNLjRv7R"},"source":["import argparse\r\n","from collections import Counter\r\n","import time\r\n","\r\n","from pyspin.spin import make_spin, Spin2\r\n","import os\r\n","import sys\r\n","\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.image as mpimg\r\n","from terminaltables import DoubleTable\r\n","\r\n","import numpy as np\r\n","from scipy.stats import energy_distance, wasserstein_distance\r\n","\r\n","\r\n","#import config as config\r\n","\"\"\"\r\n","from helpers import display_results_histogram, get_number_of_frames, get_video_filenames, get_video_fps, \\\r\n","    get_video_first_frame, print_finished_training_message, terminal_yes_no_question, show_final_match, \\\r\n","    video_file_already_stabilised\r\n","\"\"\"\r\n","from histogram import HistogramGenerator\r\n","from video_operations import VideoStabiliser\r\n","#CONFIG\r\n","\"\"\"\r\n","Contains different global variables controlling the system. They set via command line arguments.\r\n","\"\"\"\r\n","model = \"\"  # variable used to specify the histogram model to use\r\n","mode = \"\"  # variable used to specify the mode to run the program in\r\n","show_histograms = False  # Boolean used to decide whether each generated histogram should be displayed or not\r\n","debug = False  # Boolean used to print additional logs for debugging purposes\r\n","#HELPERS\r\n","def get_video_filenames(directory):\r\n","    \"\"\"\r\n","    Returns a list containing all the mp4 files in a directory\r\n","    :param directory: the directory containing mp4 files\r\n","    :return: list of strings\r\n","    \"\"\"\r\n","    list_of_videos = list()\r\n","    for filename in os.listdir(directory):\r\n","        if filename == \".DS_Store\":\r\n","            pass  # ignoring .DS_Store file (for macOS)\r\n","        elif filename.endswith(\".mp4\"):\r\n","            list_of_videos.append(filename)\r\n","        else:\r\n","            print(\"no mp4 files found in directory '{}'\".format(directory))\r\n","    return list_of_videos\r\n","\r\n","\r\n","def print_terminal_table(table_data, method_used):\r\n","    \"\"\"\r\n","    Prints a table with the results in the terminal.\r\n","    :param table_data: the data of the table\r\n","    :param method_used: the method used, to print as the table title\r\n","    :return: None\r\n","    \"\"\"\r\n","    table = DoubleTable(table_data)\r\n","    table.title = method_used\r\n","    table.inner_heading_row_border = False\r\n","    table.inner_row_border = True\r\n","    print(table.table)\r\n","\r\n","\r\n","def print_finished_training_message(answer, model, runtime, accuracy=None):\r\n","    \"\"\"\r\n","    Prints a message at the end of the training function.\r\n","    :param answer: the matched video name\r\n","    :param model: the histogram model used for training\r\n","    :param runtime: the time elapsed in seconds\r\n","    :param accuracy: the accuracy of the classifier in % (True Positives / Number of Matches)\r\n","    :return: None\r\n","    \"\"\"\r\n","    print(\"\\n\\nGenerated \" + \"\\x1b[1;31m\" + \"{}\".format(model) + \"\\x1b[0m\" + \" histograms for all videos\")\r\n","    if accuracy is not None:\r\n","        print(\"\\n\\n\" + \"\\x1b[1;31m\" + \"MATCH FOUND: {}\".format(answer) + \"\\x1b[0m\")\r\n","    print(\"\\n--- Runtime: {} seconds ---\".format(runtime))\r\n","    if accuracy is not None:\r\n","        print(\"--- Accuracy: {} % ---\".format(round(accuracy * 100, 2)))\r\n","\r\n","\r\n","def get_video_first_frame(video, path_output_dir, is_query=False, is_result=False):\r\n","    \"\"\"\r\n","    Retrieves the first frame from a video and saves it as a PNG.\r\n","    :param video: the path to the video\r\n","    :param path_output_dir: the directory to save the frame in\r\n","    :param is_query: write first frame for query\r\n","    :param is_result: write first frame for matched video\r\n","    :return: None\r\n","    \"\"\"\r\n","    vc = cv2.VideoCapture(video)\r\n","    frame_counter = 0\r\n","    while vc.isOpened():\r\n","        ret, image = vc.read()\r\n","        if ret and frame_counter == 0:\r\n","            if is_query:\r\n","                cv2.imwrite(os.path.join(path_output_dir, \"query.png\"), image)\r\n","            elif is_result:\r\n","                cv2.imwrite(os.path.join(path_output_dir, \"result.png\"), image)\r\n","            frame_counter += 1\r\n","        else:\r\n","            break\r\n","    cv2.destroyAllWindows()\r\n","    vc.release()\r\n","\r\n","\r\n","def show_final_match(result_name, query_frame, result_frame, runtime, accuracy):\r\n","    \"\"\"\r\n","    Plots the query image and the matched video.\r\n","    :param result_name: the name of the matched video\r\n","    :param query_frame: the query image\r\n","    :param result_frame: the matched video's image\r\n","    :param runtime: the time elapsed in seconds\r\n","    :param accuracy: the accuracy of the classifier in % (True Positives / Number of Matches)\r\n","    :return: None\r\n","    \"\"\"\r\n","    query_img = mpimg.imread(query_frame)\r\n","    result_img = mpimg.imread(result_frame)\r\n","    plt.subplot(2, 1, 1)\r\n","    plt.imshow(query_img)\r\n","    plt.title(\"Original Query Video\", fontSize=16), plt.xticks([]), plt.yticks([])\r\n","    plt.subplot(2, 1, 2)\r\n","    plt.imshow(result_img)\r\n","    plt.title(\r\n","        \"Match '{}' found in {}s with {}% accuracy\".format(result_name, runtime, round(accuracy * 100, 2)),\r\n","        fontSize=13)\r\n","    plt.xticks([])\r\n","    plt.yticks([])\r\n","    plt.show()\r\n","\r\n","\r\n","def display_results_histogram(results_dict):\r\n","    \"\"\"\r\n","    Displays the results in the form of a histogram.\r\n","    :param results_dict: the histogram with results and the number of matches per video\r\n","    :return: None\r\n","    \"\"\"\r\n","    fig = plt.figure()\r\n","    ax = fig.add_subplot(111)\r\n","    ax.bar(list(results_dict.keys()), results_dict.values())\r\n","    plt.title(\"Probability of a match for most likely videos\")\r\n","    plt.ylabel(\"%\")\r\n","    plt.tight_layout()\r\n","    plt.setp(ax.get_xticklabels(), fontsize=10, rotation='vertical')\r\n","    plt.show()\r\n","\r\n","\r\n","def get_number_of_frames(vc):\r\n","    \"\"\"\r\n","    Retrieves the total number of frames in a video using OpenCV's VideoCapture object cv2.CAP_PROP_FRAME_COUNT\r\n","    attribute.\r\n","    :param vc: the video capture\r\n","    :return: the number of frames in the video capture\r\n","    \"\"\"\r\n","    return int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\r\n","\r\n","\r\n","def get_video_fps(vc):\r\n","    \"\"\"\r\n","    Retrieves the frame rate (Frames Per Second) of a video using OpenCV's VideoCapture object cv2.CAP_PROP_FPS\r\n","    attribute.\r\n","    :param vc: the video capture\r\n","    :return: the video capture's FPS\r\n","    \"\"\"\r\n","    return round(vc.get(cv2.CAP_PROP_FPS), 2)\r\n","\r\n","\r\n","def terminal_yes_no_question(question, default=\"no\"):\r\n","    \"\"\"\r\n","    Ask a yes/no question via input() and return the answer as a boolean.\r\n","    :param question: string that is presented in the terminal\r\n","    :param default: presumed answer if <Enter> directly hit with no answer\r\n","    :return: True for \"yes\" or False for \"no\"\r\n","    \"\"\"\r\n","    valid = {\"yes\": True, \"y\": True, \"no\": False, \"n\": False}\r\n","\r\n","    if default is None:\r\n","        prompt = \" [y/n] \"\r\n","    elif default == \"yes\":\r\n","        prompt = \" [Y/n] \"\r\n","    elif default == \"no\":\r\n","        prompt = \" [y/N] \"\r\n","    else:\r\n","        raise ValueError(\"invalid default answer: '%s'\" % default)\r\n","\r\n","    while True:\r\n","        sys.stdout.write(question + prompt)\r\n","        choice = input().lower()\r\n","        if default is not None and choice == '':\r\n","            return valid[default]\r\n","        elif choice in valid:\r\n","            return valid[choice]\r\n","        else:\r\n","            sys.stdout.write(\"Please respond with 'yes' or 'no' (or 'y' or 'n').\\n\")\r\n","\r\n","#VIDEO_OPERATIONS\r\n","from pyspin.spin import make_spin, Box1\r\n","from vidstab import VidStab\r\n","\r\n","class ClickAndDrop:\r\n","    \"\"\"\r\n","    Class for selecting a region of interest on a frame by click and dropping the mouse over the desired area, and\r\n","    cropping that frame to include the pixels inside the ROI only.\r\n","    \"\"\"\r\n","    frame_size = (1280, 720)\r\n","    window_name = \"Crop the recording (top-left click -> bottom-right drop) - 'C' to crop - 'R' to restart\"\r\n","\r\n","    def __init__(self, thumbnail):\r\n","        \"\"\"\r\n","        Loads the image to crop and controls the callback loop. Calculates the reference points once a valid cropped\r\n","        area has been chosen and the user has clicked \"c\".\r\n","        :param thumbnail: the first frame of the video to crop\r\n","        \"\"\"\r\n","        self.thumbnail = thumbnail\r\n","\r\n","        self.reference_points = list()\r\n","        self.cropping = False\r\n","\r\n","        # load the image, clone it, and setup the mouse callback function\r\n","        self.image = cv2.resize(self.thumbnail, self.frame_size, interpolation=cv2.INTER_AREA)\r\n","        clone = self.image.copy()\r\n","        cv2.namedWindow(self.window_name)\r\n","        cv2.setMouseCallback(self.window_name, self.click_and_crop)\r\n","\r\n","        # keep looping until the 'q' key is pressed\r\n","        while True:\r\n","            # display the image and wait for a keypress\r\n","            cv2.imshow(self.window_name, self.image)\r\n","            key = cv2.waitKey(1) & 0xFF\r\n","            if key == ord(\"r\"):  # reset the cropping region\r\n","                self.image = clone.copy()\r\n","            elif key == ord(\"c\"):  # break from the loop\r\n","                break\r\n","\r\n","        # if there are 2 reference points, then crop the region of interest from the image\r\n","        if len(self.reference_points) == 2:\r\n","            self.roi = clone[self.reference_points[0][1]:self.reference_points[1][1],\r\n","                             self.reference_points[0][0]:self.reference_points[1][0]]\r\n","\r\n","        # close all open windows\r\n","        cv2.destroyAllWindows()\r\n","\r\n","    def click_and_crop(self, event, x, y, flags, param):\r\n","        \"\"\"\r\n","        Callback function allowing a user to manually crop an image.\r\n","\r\n","        NOTE: must crop from top-left corner to bottom-right corner\r\n","\r\n","        :param event: one of the MouseEventTypes constants\r\n","        :param x: the x-coordinate of the mouse event\r\n","        :param y: the y-coordinate of the mouse event\r\n","        :param flags: one of the MouseEventFlags constants\r\n","        :param param: optional parameters\r\n","        :return: None\r\n","        \"\"\"\r\n","        # if the left mouse button was clicked, record the starting (x, y) coordinates and indicate that cropping is\r\n","        # being performed\r\n","        if event == cv2.EVENT_LBUTTONDOWN:\r\n","            self.reference_points = [(x, y)]\r\n","            self.cropping = True\r\n","\r\n","        # check to see if the left mouse button was released\r\n","        elif event == cv2.EVENT_LBUTTONUP:\r\n","            # record the ending (x, y) coordinates and indicate that the cropping operation is finished\r\n","            self.reference_points.append((x, y))\r\n","            self.cropping = False\r\n","\r\n","            # draw a rectangle around the region of interest\r\n","            cv2.rectangle(self.image, self.reference_points[0], self.reference_points[1], (0, 255, 0), 2)\r\n","            cv2.imshow(self.window_name, self.image)\r\n","\r\n","    def get_roi(self):\r\n","        \"\"\"\r\n","        Return the selected region of interest of the frame.\r\n","        :return: roi: the user-cropped region of the image\r\n","        \"\"\"\r\n","        return self.roi\r\n","\r\n","    def get_reference_points(self):\r\n","        \"\"\"\r\n","        Returns the ROI's reference points coordinates\r\n","        :return: reference_points: a list containing the two x and y coordinates used to crop the image.\r\n","        \"\"\"\r\n","        return self.reference_points\r\n","\r\n","\r\n","class VideoStabiliser:\r\n","    \"\"\"\r\n","    Class used to stabilise the recorded video for more optimal matching.\r\n","    \"\"\"\r\n","    def __init__(self, directory, file_name):\r\n","        \"\"\"\r\n","        Initialise variables and call the function to stabilise the specified video.\r\n","        :param directory: the directory where the video file to stabilise is located\r\n","        :param file_name: the mp4 video file's name\r\n","        \"\"\"\r\n","        self.directory = directory\r\n","        self.file = file_name\r\n","        self.new_file = file_name[:-4]\r\n","\r\n","        self.stabiliser = VidStab()\r\n","        self.stabilise_video()\r\n","\r\n","    @make_spin(Box1, \"Stabilising video...\")\r\n","    def stabilise_video(self):\r\n","        \"\"\"\r\n","        Stabilises a mp4 video and outputs the result as an avi file in the same directory.\r\n","        :return:\r\n","        \"\"\"\r\n","        self.stabiliser.stabilize(input_path=\"{}{}\".format(self.directory, self.file),\r\n","                                  output_path=\"{}/stable-{}.avi\".format(self.directory, self.new_file),\r\n","                                  border_type=\"reflect\")\r\n","        print(\"\\nVideo stabilised!\")\r\n","\r\n","\r\n","#MAIN\r\n","\r\n","def main():\r\n","    \"\"\"\r\n","    Program entry point. Parses command line input to decide which phase of the system to run.\r\n","    :return: None\r\n","    \"\"\"\r\n","    parser = argparse.ArgumentParser()\r\n","    parser.add_argument(\"-m\", \"--model\",\r\n","                        help=\"The histogram model to use. Choose from the following options: 'rgb', 'hsv' or 'gray'. \"\r\n","                             \"Leave empty to train using all 3 histogram models.\")\r\n","    parser.add_argument(\"--mode\",\r\n","                        required=True,\r\n","                        help=\"The mode to run the code in. Choose from the following options: 'train', 'test' or \"\r\n","                             \"'segment'.\")\r\n","    parser.add_argument(\"--showhists\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to display each generated histogram.\")\r\n","    parser.add_argument(\"-d\", \"--debug\",\r\n","                        action=\"store_true\",\r\n","                        help=\"Specify whether you want to print additional logs for debugging purposes.\")\r\n","    args = parser.parse_args()\r\n","    config.debug = args.debug\r\n","    config.mode = args.mode\r\n","    config.show_histograms = args.showhists\r\n","    config.model = args.model\r\n","\r\n","    if config.mode == \"train\":\r\n","        off_line_colour_based_feature_extraction_phase()\r\n","    elif config.mode == \"test\":\r\n","        on_line_retrieval_phase()\r\n","    elif config.mode == \"segment\":\r\n","        database_preprocessing_phase()\r\n","    else:\r\n","        print(\"Wrong mode chosen. Choose from the following options: 'train', 'test' or 'segment'.\")\r\n","        exit(0)\r\n","\r\n","\r\n","@make_spin(Spin2, \"Generating histograms for database videos...\".format(config.model))\r\n","def off_line_colour_based_feature_extraction_phase():\r\n","    \"\"\"\r\n","    Generates and stores averaged greyscale, RGB and HSV histograms for all the videos in the directory-based database.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/footage/\"\r\n","    files = get_video_filenames(directory)\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    for file in files:\r\n","        if config.model == \"gray\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_greyscale_histogram()\r\n","        elif config.model == \"rgb\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_rgb_histogram()\r\n","        elif config.model == \"hsv\":\r\n","            histogram_generator = HistogramGenerator(directory, file)\r\n","            histogram_generator.generate_video_hsv_histogram()\r\n","        else:\r\n","            histogram_generator_gray = HistogramGenerator(directory, file)\r\n","            histogram_generator_gray.generate_video_greyscale_histogram()\r\n","            histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","            histogram_generator_rgb.generate_video_rgb_histogram()\r\n","            histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","            histogram_generator_hsv.generate_video_hsv_histogram()\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print_finished_training_message(config.model, directory, runtime)\r\n","\r\n","\r\n","def on_line_retrieval_phase():\r\n","    \"\"\"\r\n","    Prompts the user to stabilise and crop the query video before generating the same averaged greyscale, RGB and HSV\r\n","    histograms to compare with the database videos' previously stored histograms using distance metrics.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/\"\r\n","    recordings = [\"recording1.mp4\", \"recording2.mp4\", \"recording3.mp4\", \"recording4.mp4\", \"recording5.mp4\",\r\n","                  \"recording6.mp4\", \"recording7.mp4\", \"recording8.mp4\"]\r\n","    mismatches_directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/mismatches/\"\r\n","    mismatches = [\"mismatch1.mp4\", \"mismatch2.mp4\"]\r\n","    # 0: cloudy-sky, 1: seal, 2: butterfly (skewed), 3: wind-turbine, 4: ice-hockey, 5: jellyfish, 6: people-dancing,\r\n","    # 7: jellyfish (skewed)\r\n","    file = recordings[7]\r\n","\r\n","    # ask user to stabilise the input query video or not\r\n","    is_stabilise_video = terminal_yes_no_question(\"Do you wish to stabilise the recorded query video?\")\r\n","    stable_filename = \"stable-\" + file[:-4] + \".avi\"  # the stable version of the video\r\n","    # yes: stabilise the video and use the stable .avi version\r\n","    if is_stabilise_video:\r\n","        if not video_file_already_stabilised(directory + stable_filename):\r\n","            VideoStabiliser(directory, \"{}\".format(file))\r\n","        print(\"\\nStabilised version of query already found: '{}'\".format(stable_filename))\r\n","        file = stable_filename\r\n","    # no: check if a version of the stabilised video doesn't already exist - use it if it does\r\n","    else:\r\n","        if video_file_already_stabilised(directory + stable_filename):\r\n","            file = stable_filename\r\n","\r\n","    print(\"\\nUsing query: '{}'\".format(file))\r\n","    print(\"\\nPlease crop the recorded query video for the signature to be generated.\")\r\n","\r\n","    if config.model == \"gray\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_greyscale_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"rgb\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_rgb_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    elif config.model == \"hsv\":\r\n","        histogram_generator = HistogramGenerator(directory, file)\r\n","        histogram_generator.generate_video_hsv_histogram(is_query=True)\r\n","        histogram_generator.match_histograms()\r\n","    else:\r\n","        # calculate query histogram\r\n","        # greyscale\r\n","        histogram_generator_gray = HistogramGenerator(directory, file)\r\n","        histogram_generator_gray.generate_video_greyscale_histogram(is_query=True)\r\n","        cur_reference_points = histogram_generator_gray.get_current_reference_points()\r\n","        # start measuring runtime (after manual cropping)\r\n","        start_time = time.time()\r\n","        # RGB\r\n","        histogram_generator_rgb = HistogramGenerator(directory, file)\r\n","        histogram_generator_rgb.generate_video_rgb_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","        # HSV\r\n","        histogram_generator_hsv = HistogramGenerator(directory, file)\r\n","        histogram_generator_hsv.generate_video_hsv_histogram(is_query=True, cur_ref_points=cur_reference_points)\r\n","\r\n","        # calculate distances between query and DB histograms\r\n","        histogram_generator_gray.match_histograms(cur_all_model='gray')\r\n","        histogram_generator_rgb.match_histograms(cur_all_model='rgb')\r\n","        histogram_generator_hsv.match_histograms(cur_all_model='hsv')\r\n","\r\n","        # Combine matches from all 3 histogram models to output one final result\r\n","        all_results = histogram_generator_hsv.get_results_array()  # array of all matches made (using weights)\r\n","        results_count = Counter(all_results)  # count the number of matches made for each video in all_results array\r\n","        # transform from count to percentage of matches made\r\n","        results_percentage = dict()\r\n","        for match in results_count:\r\n","            percentage = round((results_count[match] / len(all_results)) * 100.0, 2)\r\n","            results_percentage[match] = percentage\r\n","        display_results_histogram(results_percentage)\r\n","        print(\"Matches made: {}\".format(results_count))\r\n","        print(\"% of matches made: {}\".format(results_percentage))\r\n","\r\n","        # find best result\r\n","        final_result_name = \"\"\r\n","        final_result_count = 0\r\n","        for i, r in enumerate(results_count):\r\n","            if i == 0:\r\n","                final_result_name = r\r\n","                final_result_count = results_count[r]\r\n","            else:\r\n","                if results_count[r] > final_result_count:\r\n","                    final_result_name = r\r\n","                    final_result_count = results_count[r]\r\n","\r\n","        # print results\r\n","        runtime = round(time.time() - start_time, 2)\r\n","        accuracy = final_result_count / len(all_results)\r\n","        get_video_first_frame(directory + file, \"/content/Content-Based-Video-Retrieval-Code/results\", is_query=True)\r\n","        get_video_first_frame(\"/content/Content-Based-Video-Retrieval-Code/footage/{}\".format(final_result_name), \"../results\", is_result=True)\r\n","        show_final_match(final_result_name, \"/content/Content-Based-Video-Retrieval-Code/results/query.png\", \"/content/Content-Based-Video-Retrieval-Code/results/result.png\", runtime, accuracy)\r\n","        print_finished_training_message(final_result_name, config.model, runtime, accuracy)\r\n","\r\n","\r\n","def database_preprocessing_phase():\r\n","    \"\"\"\r\n","    Applies a shot boundary detection algorithm to a video for segmentation.\r\n","    :return: None\r\n","    \"\"\"\r\n","    directory = \"/content/Content-Based-Video-Retrieval-Code/recordings/\"\r\n","    video = \"scene-segmentation.mp4\"\r\n","    # directory = \"/Volumes/ADAM2/\"\r\n","    # movies = [\"Inception (2010).mp4\"]\r\n","    # video = movies[0]\r\n","\r\n","    shot_boundary_detector = HistogramGenerator(directory, video)\r\n","    video_capture = shot_boundary_detector.get_video_capture()\r\n","    frame_count = get_number_of_frames(vc=video_capture)\r\n","    fps = get_video_fps(vc=video_capture)\r\n","    print(\"Total Frames: {}\".format(frame_count))\r\n","    print(\"FPS: {}\\n\".format(fps))\r\n","\r\n","    # start measuring runtime\r\n","    start_time = time.time()\r\n","\r\n","    # start processing video for shout boundary detection\r\n","    print(\"Starting to process video for shot boundary detection...\")\r\n","    shot_boundary_detector.rgb_histogram_shot_boundary_detection(threshold=7)\r\n","\r\n","    # print final results\r\n","    runtime = round(time.time() - start_time, 2)\r\n","    print(\"--- Number of frames in video: {} ---\".format(frame_count))\r\n","    print(\"--- Runtime: {} seconds ---\".format(runtime))\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uj4YQrKpRwHh"},"source":["import csv\r\n","import math\r\n","import os\r\n","\r\n","import cv2\r\n","from matplotlib import pyplot as plt\r\n","import numpy as np\r\n","from scipy.stats import energy_distance, wasserstein_distance\r\n","\r\n","import app.config as config\r\n","from app.helpers import get_video_filenames, print_terminal_table\r\n","from app.video_operations import ClickAndDrop\r\n","\r\n","\r\n","class HistogramGenerator:\r\n","    colours = ('b', 'g', 'r')  # RGB channels\r\n","    bins = (8, 12, 3)  # 8 hue bins, 12 saturation bins, 3 value bins\r\n","    histcmp_methods = [cv2.HISTCMP_CORREL, cv2.HISTCMP_CHISQR, cv2.HISTCMP_INTERSECT, cv2.HISTCMP_HELLINGER]\r\n","    histcmp_3d_methods = [\"earths_mover_distance\", \"energy_distance\"]\r\n","    histogram_comparison_weigths = {  # weights per comparison methods\r\n","        'gray': 1,\r\n","        'rgb': 5,\r\n","        'hsv': 10\r\n","    }\r\n","    results_array = list()\r\n","\r\n","    def __init__(self, directory, file_name):\r\n","        \"\"\"\r\n","        Initialise variables and create a VideoCapture object for a mp4 file.\r\n","        :param directory: the directory where the video file is located\r\n","        :param file_name: the mp4 video file's name\r\n","        \"\"\"\r\n","        self.directory = directory\r\n","        self.file_name = file_name\r\n","\r\n","        # start capturing video\r\n","        self.video_capture = cv2.VideoCapture(\"{}{}\".format(self.directory, self.file_name))\r\n","        self.check_video_capture()\r\n","\r\n","        # dicts of lists to store histograms for each frame\r\n","        self.histograms_grey_dict = list()\r\n","        self.histograms_rgb_dict = {\r\n","            'b': list(),\r\n","            'g': list(),\r\n","            'r': list()\r\n","        }\r\n","        self.histograms_hsv_dict = list()\r\n","\r\n","        # keep current ROI for re-use\r\n","        self.reference_points = list()\r\n","\r\n","    def generate_video_rgb_histogram(self, is_query=False, cur_ref_points=None):\r\n","        \"\"\"\r\n","        Generates multiple RGB histograms (one every second) for a video.\r\n","        :param is_query: boolean specifying if the input video is the query video (to select ROI)\r\n","        :param cur_ref_points: list of previously-used ROI point locations\r\n","        :return: None\r\n","        \"\"\"\r\n","        # determine which frames to process for histograms\r\n","        frames_to_process = _get_frames_to_process(self.video_capture)\r\n","\r\n","        frame_counter = 0  # keep track of current frame ID to know to process it or not\r\n","        while self.video_capture.isOpened():\r\n","            ret, frame = self.video_capture.read()  # read capture frame by frame\r\n","            if ret:\r\n","                if is_query and frame_counter == 0:\r\n","                    if cur_ref_points is None:\r\n","                        cad = ClickAndDrop(frame)\r\n","                        if config.debug:  # show the cropped region of interest\r\n","                            roi_frame = cad.get_roi()\r\n","                            cv2.imshow(\"Selected ROI\", roi_frame)\r\n","                            cv2.waitKey(0)\r\n","                        self.reference_points = cad.get_reference_points()\r\n","                    else:\r\n","                        self.reference_points = cur_ref_points\r\n","                frame_counter += 1\r\n","                if frame_counter in frames_to_process:\r\n","                    for i, col in enumerate(self.colours):\r\n","                        if is_query and len(self.reference_points) == 2:\r\n","                            roi = frame[self.reference_points[0][1]:self.reference_points[1][1],\r\n","                                        self.reference_points[0][0]:self.reference_points[1][0]]\r\n","                            histogram = cv2.calcHist([roi], [i], None, [256], [0, 256])\r\n","                        else:\r\n","                            histogram = cv2.calcHist([frame], [i], None, [256], [0, 256])\r\n","                        self.histograms_rgb_dict[col].append(histogram)\r\n","                        if config.debug:  # show individual BGR histogram plots\r\n","                            print(\"i: {}, col: {}\".format(i, col))\r\n","                            plt.plot(histogram, color=col)\r\n","                            plt.xlim([0, 256])\r\n","                    if config.debug:\r\n","                        plt.show()\r\n","\r\n","                    # user exit on \"q\" or \"Esc\" key press\r\n","                    k = cv2.waitKey(30) & 0xFF\r\n","                    if k == 25 or k == 27:\r\n","                        break\r\n","            else:\r\n","                break\r\n","        self.generate_and_store_average_rgb_histogram()\r\n","        self.destroy_video_capture()\r\n","\r\n","    def generate_video_greyscale_histogram(self, is_query=False):\r\n","        \"\"\"\r\n","        Generates multiple greyscale histograms (one every second) for a video.\r\n","        :param is_query: boolean specifying if the input video is the query video (to select ROI)\r\n","        :return: None\r\n","        \"\"\"\r\n","        # determine which frames to process for histograms\r\n","        frames_to_process = _get_frames_to_process(self.video_capture)\r\n","\r\n","        frame_counter = 0  # keep track of current frame ID to know to process it or not\r\n","        while self.video_capture.isOpened():\r\n","            ret, frame = self.video_capture.read()  # read capture frame by frame\r\n","            if ret:\r\n","                if is_query and frame_counter == 0:\r\n","                    cad = ClickAndDrop(frame)\r\n","                    if config.debug:  # show the cropped region of interest\r\n","                        roi_frame = cad.get_roi()\r\n","                        cv2.imshow(\"Selected ROI\", roi_frame)\r\n","                        cv2.waitKey(0)\r\n","                    self.reference_points = cad.get_reference_points()\r\n","                frame_counter += 1\r\n","                if frame_counter in frames_to_process:\r\n","                    if is_query and len(self.reference_points) == 2:\r\n","                        roi = frame[self.reference_points[0][1]:self.reference_points[1][1],\r\n","                                    self.reference_points[0][0]:self.reference_points[1][0]]\r\n","                        roi_grey = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\r\n","                        histogram = cv2.calcHist([roi_grey], [0], None, [256], [0, 256])\r\n","                    else:\r\n","                        grey_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n","                        histogram = cv2.calcHist([grey_frame], [0], None, [256], [0, 256])\r\n","                    self.histograms_grey_dict.append(histogram)\r\n","                    if config.debug:  # show individual greyscale histogram plots\r\n","                        plt.figure()\r\n","                        plt.title(\"{} frame {}\".format(self.file_name, frame_counter))\r\n","                        plt.xlabel(\"Bins\")\r\n","                        plt.plot(histogram)\r\n","                        plt.xlim([0, 256])\r\n","                        plt.show()\r\n","\r\n","                    # user exit on \"q\" or \"Esc\" key press\r\n","                    k = cv2.waitKey(30) & 0xFF\r\n","                    if k == 25 or k == 27:\r\n","                        break\r\n","            else:\r\n","                break\r\n","        self.generate_and_store_average_greyscale_histogram()\r\n","        self.destroy_video_capture()\r\n","\r\n","    def generate_video_hsv_histogram(self, is_query=False, cur_ref_points=None):\r\n","        \"\"\"\r\n","        Generates multiple HSV histograms (one every second) for a video.\r\n","        :param is_query: boolean specifying if the input video is the query video (to select ROI)\r\n","        :param cur_ref_points: list of previously-used ROI point locations\r\n","        :return: None\r\n","        \"\"\"\r\n","        # determine which frames to process for histograms\r\n","        frames_to_process = _get_frames_to_process(self.video_capture)\r\n","\r\n","        frame_counter = 0  # keep track of current frame ID to know to process it or not\r\n","        while self.video_capture.isOpened():\r\n","            ret, frame = self.video_capture.read()  # read capture frame by frame\r\n","            if ret:\r\n","                if is_query and frame_counter == 0:\r\n","                    if cur_ref_points is None:\r\n","                        cad = ClickAndDrop(frame)\r\n","                        if config.debug:  # show the cropped region of interest\r\n","                            roi_frame = cad.get_roi()\r\n","                            cv2.imshow(\"Selected ROI\", roi_frame)\r\n","                            cv2.waitKey(0)\r\n","                        self.reference_points = cad.get_reference_points()\r\n","                    else:\r\n","                        self.reference_points = cur_ref_points\r\n","                frame_counter += 1\r\n","                if frame_counter in frames_to_process:\r\n","                    if is_query and len(self.reference_points) == 2:\r\n","                        roi = frame[self.reference_points[0][1]:self.reference_points[1][1],\r\n","                                    self.reference_points[0][0]:self.reference_points[1][0]]\r\n","                        roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\r\n","                        histogram = cv2.calcHist([roi_hsv], [0, 1, 2], None, self.bins, [0, 180, 0, 256, 0, 256])\r\n","                    else:\r\n","                        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\r\n","                        histogram = cv2.calcHist([hsv_frame], [0, 1, 2], None, self.bins, [0, 180, 0, 256, 0, 256])\r\n","                    self.histograms_hsv_dict.append(histogram)\r\n","                    if config.debug:  # show individual HSV histogram plots\r\n","                        plt.imshow(histogram)\r\n","                        plt.title(\"{} frame {}\".format(self.file_name, frame_counter))\r\n","                        plt.show()\r\n","\r\n","                    # user exit on \"q\" or \"Esc\" key press\r\n","                    k = cv2.waitKey(30) & 0xFF\r\n","                    if k == 25 or k == 27:\r\n","                        break\r\n","            else:\r\n","                break\r\n","        self.generate_and_store_average_hsv_histogram()\r\n","        self.destroy_video_capture()\r\n","\r\n","    def generate_and_store_average_rgb_histogram(self):\r\n","        \"\"\"\r\n","        Generates a single RGB histogram by averaging all histograms of a video before normalising it and saving the\r\n","        results to a plain text file.\r\n","        :return: None\r\n","        \"\"\"\r\n","        avg_histogram = np.zeros(shape=(255, 1))  # array to store average histogram values\r\n","        for col, hists in self.histograms_rgb_dict.items():\r\n","            for i in range(0, 255):  # loop through all bins\r\n","                bin_sum = 0\r\n","\r\n","                # get value for each colour histogram in bin i\r\n","                for arr_index in range(0, len(hists)):\r\n","                    bin_value = hists[arr_index].item(i)\r\n","                    bin_sum += bin_value\r\n","\r\n","                # average all bins values to store in new histogram\r\n","                new_bin_value = bin_sum / len(hists)\r\n","                avg_histogram[i] = new_bin_value\r\n","\r\n","            # normalise averaged histogram\r\n","            avg_histogram = _normalise_histogram(avg_histogram)\r\n","\r\n","            # write to file\r\n","            if not os.path.exists(\"../histogram_data/{}/\".format(self.file_name)):\r\n","                os.makedirs(\"../histogram_data/{}/\".format(self.file_name))\r\n","            with open(\"../histogram_data/{}/hist-{}.txt\".format(self.file_name, col), 'w') as file:\r\n","                file.write(\"# '{}' channel of RGB histogram ({} bins) [normalised]\\n\".format(\r\n","                    col.upper(),\r\n","                    avg_histogram.shape[0]\r\n","                ))\r\n","                np.savetxt(file, avg_histogram, fmt='%f')\r\n","            if config.show_histograms:\r\n","                plt.plot(avg_histogram, color=col)\r\n","                plt.xlim([0, 256])\r\n","        if config.show_histograms:\r\n","            plt.title(\"RGB histogram for '{}'\".format(self.file_name))\r\n","            plt.xlabel(\"Bins\")\r\n","            plt.show()\r\n","\r\n","    def generate_and_store_average_greyscale_histogram(self):\r\n","        \"\"\"\r\n","        Generates a single greyscale histogram by averaging all histograms of a video before normalising it and saving\r\n","        the results to a plain text file.\r\n","        :return: None\r\n","        \"\"\"\r\n","        avg_histogram = np.zeros(shape=(255, 1))  # array to store average histogram values\r\n","\r\n","        col = \"gray\"\r\n","        hist = self.histograms_grey_dict\r\n","\r\n","        for i in range(0, 255):  # loop through all bins\r\n","            bin_sum = 0\r\n","\r\n","            # get value for each colour histogram in bin i\r\n","            for arr_index in range(0, len(hist)):\r\n","                bin_value = hist[arr_index].item(i)\r\n","                bin_sum += bin_value\r\n","\r\n","            # average all bins values to store in new histogram\r\n","            new_bin_value = bin_sum / len(hist)\r\n","            avg_histogram[i] = new_bin_value\r\n","\r\n","        # normalise averaged histogram\r\n","        avg_histogram = _normalise_histogram(avg_histogram)\r\n","\r\n","        # write to file\r\n","        if not os.path.exists(\"../histogram_data/{}/\".format(self.file_name)):\r\n","            os.makedirs(\"../histogram_data/{}/\".format(self.file_name))\r\n","        with open(\"../histogram_data/{}/hist-{}.txt\".format(self.file_name, col), 'w') as file:\r\n","            file.write(\"# Greyscale Histogram ({} bins) [normalised]\\n\".format(avg_histogram.shape[0]))\r\n","            np.savetxt(file, avg_histogram, fmt='%f')\r\n","        if config.show_histograms:\r\n","            plt.plot(avg_histogram, color=col)\r\n","            plt.xlim([0, 256])\r\n","            plt.title(\"Greyscale histogram for '{}'\".format(self.file_name))\r\n","            plt.xlabel(\"Bins\")\r\n","            plt.show()\r\n","\r\n","    def generate_and_store_average_hsv_histogram(self):\r\n","        \"\"\"\r\n","        Generates a single HSV histogram by averaging all histograms of a video before normalising it and saving the\r\n","        results to a plain text file.\r\n","        :return: None\r\n","        \"\"\"\r\n","        avg_histogram = np.zeros(shape=(8, 12, 3))  # array to store average histogram values\r\n","\r\n","        col = \"hsv\"\r\n","        hist = self.histograms_hsv_dict\r\n","\r\n","        for h in range(0, self.bins[0]):  # loop through hue bins\r\n","            for s in range(0, self.bins[1]):  # loop through saturation bins\r\n","                for v in range(0, self.bins[2]):  # loop through value bins\r\n","                    bin_sum = 0\r\n","\r\n","                    # get value for each colour histogram in bin [h][s][v]\r\n","                    for arr_index in range(0, len(hist)):\r\n","                        bin_value = hist[arr_index][h][s][v]\r\n","                        bin_sum += bin_value\r\n","\r\n","                    # average all bins values to store in new histogram\r\n","                    new_bin_value = bin_sum / len(hist)\r\n","                    avg_histogram[h][s][v] = new_bin_value\r\n","\r\n","        # normalise averaged histogram\r\n","        avg_histogram = _normalise_histogram(avg_histogram)\r\n","\r\n","        # write to file\r\n","        if not os.path.exists(\"../histogram_data/{}/\".format(self.file_name)):\r\n","            os.makedirs(\"../histogram_data/{}/\".format(self.file_name))\r\n","        with open(\"../histogram_data/{}/hist-{}.txt\".format(self.file_name, col), 'w') as file:\r\n","            file.write(\"# HSV Histogram shape: {0} [normalised]\\n\".format(avg_histogram.shape))\r\n","            for arr_2d in avg_histogram:\r\n","                file.write(\"# New slice\\n\")\r\n","                np.savetxt(file, arr_2d)\r\n","\r\n","        if config.show_histograms:\r\n","            plt.imshow(avg_histogram)\r\n","            plt.title(\"HSV histogram for '{}'\".format(self.file_name))\r\n","            plt.xlabel(\"Hue\")\r\n","            plt.ylabel(\"Saturation\")\r\n","            plt.show()\r\n","\r\n","    def match_histograms(self, cur_all_model=\"all\"):\r\n","        \"\"\"\r\n","        Compares the greyscale, RGB and HSV histograms of the query video with each of the saved average histograms\r\n","        using different distance metrics such as the Correlation, Intersection, Chi-Square Distance, Hellinger Distance,\r\n","        Earth's Mover Distance and Energy Distance metrics. Finally, prints the results for each histogram model and\r\n","        metric in a console table and writes the data to a CSV file.\r\n","        :param cur_all_model: the current histogram model when operating with all 3 models\r\n","        :return: None\r\n","        \"\"\"\r\n","        # variables used for finding the match to the recorded video\r\n","        video_match = \"\"\r\n","        video_match_value = 0\r\n","\r\n","        # get histogram for the recorded video to match - todo: calculate the histogram on the go\r\n","        query_histogram = dict()\r\n","        if config.model == \"gray\" or (cur_all_model == \"gray\" and config.model == \"all\"):\r\n","            query_histogram = {\r\n","                'gray': np.loadtxt(\r\n","                    \"../histogram_data/{}/hist-gray.txt\".format(self.file_name),\r\n","                    dtype=np.float32,\r\n","                    unpack=False\r\n","                )\r\n","            }\r\n","        elif config.model == \"rgb\" or (cur_all_model == \"rgb\" and config.model == \"all\"):\r\n","            query_histogram = {\r\n","                'b': np.loadtxt(\"../histogram_data/{}/hist-b.txt\".format(self.file_name), dtype=np.float32, unpack=False),\r\n","                'g': np.loadtxt(\"../histogram_data/{}/hist-g.txt\".format(self.file_name), dtype=np.float32, unpack=False),\r\n","                'r': np.loadtxt(\"../histogram_data/{}/hist-r.txt\".format(self.file_name), dtype=np.float32, unpack=False)\r\n","            }\r\n","        elif config.model == \"hsv\" or (cur_all_model == \"hsv\" and config.model == \"all\"):\r\n","            hsv_data = np.loadtxt(\"../histogram_data/{}/hist-hsv.txt\".format(self.file_name))\r\n","            query_histogram = {\r\n","                'hsv': hsv_data.reshape((8, 12, 3))\r\n","            }\r\n","\r\n","        # compare query histogram with each DB video histogram\r\n","        print(\"\\n{} Histogram Comparison Results:\\n\".format(_get_chosen_model_string(cur_all_model)))\r\n","\r\n","        method = \"\"\r\n","        csv_field_names = [\"video\", \"score\"]\r\n","\r\n","        # use OpenCV's compareHist function for RGB and greyscale histograms (works with 2d arrays only)\r\n","        if config.model == \"rgb\" \\\r\n","                or config.model == \"gray\" \\\r\n","                or (cur_all_model == \"gray\" and config.model == \"all\") \\\r\n","                or (cur_all_model == \"rgb\" and config.model == \"all\"):\r\n","            for m in self.histcmp_methods:\r\n","                if m == 0:\r\n","                    method = \"CORRELATION\"\r\n","                elif m == 1:\r\n","                    method = \"CHI-SQUARE\"\r\n","                elif m == 2:\r\n","                    method = \"INTERSECTION\"\r\n","                elif m == 3:\r\n","                    method = \"HELLINGER\"\r\n","\r\n","                # CSV file to write data to for each method\r\n","                if config.model == \"all\":\r\n","                    csv_file = open(\"../results/csv/{}-{}-{}.csv\".format(config.model, cur_all_model, method), 'w')\r\n","                else:\r\n","                    csv_file = open(\"../results/csv/{}-{}.csv\".format(config.model, method), 'w')\r\n","                with csv_file:\r\n","                    writer = csv.DictWriter(csv_file, fieldnames=csv_field_names)\r\n","                    writer.writeheader()\r\n","\r\n","                    table_data = list()\r\n","                    for i, file in enumerate(get_video_filenames(\"../footage/\")):\r\n","                        comparison = 0\r\n","                        if config.model == \"gray\" or (cur_all_model == \"gray\" and config.model == \"all\"):\r\n","                            dbvideo_greyscale_histogram = np.loadtxt(\"../histogram_data/{}/hist-gray.txt\".format(file), dtype=np.float32, unpack=False)\r\n","                            comparison = cv2.compareHist(query_histogram['gray'], dbvideo_greyscale_histogram, m)\r\n","                        elif config.model == \"rgb\" or (cur_all_model == \"rgb\" and config.model == \"all\"):\r\n","                            dbvideo_b_histogram = np.loadtxt(\"../histogram_data/{}/hist-b.txt\".format(file), dtype=np.float32, unpack=False)\r\n","                            dbvideo_g_histogram = np.loadtxt(\"../histogram_data/{}/hist-g.txt\".format(file), dtype=np.float32, unpack=False)\r\n","                            dbvideo_r_histogram = np.loadtxt(\"../histogram_data/{}/hist-r.txt\".format(file), dtype=np.float32, unpack=False)\r\n","                            comparison_b = cv2.compareHist(query_histogram['b'], dbvideo_b_histogram, m)\r\n","                            comparison_g = cv2.compareHist(query_histogram['g'], dbvideo_g_histogram, m)\r\n","                            comparison_r = cv2.compareHist(query_histogram['r'], dbvideo_r_histogram, m)\r\n","                            comparison = (comparison_b + comparison_g + comparison_r) / 3\r\n","\r\n","                        # append data to table\r\n","                        table_data.append([file, round(comparison, 5)])\r\n","\r\n","                        # write data to CSV file\r\n","                        writer.writerow({\"video\": file, \"score\": round(comparison, 5)})\r\n","\r\n","                        if i == 0:\r\n","                            video_match = file\r\n","                            video_match_value = comparison\r\n","                        else:\r\n","                            # Higher score = better match (Correlation and Intersection)\r\n","                            if m in [0, 2] and comparison > video_match_value:\r\n","                                video_match = file\r\n","                                video_match_value = comparison\r\n","                            # Lower score = better match\r\n","                            # (Chi-square, Alternative chi-square, Hellinger and Kullback-Leibler Divergence)\r\n","                            elif m in [1, 3, 4, 5] and comparison < video_match_value:\r\n","                                video_match = file\r\n","                                video_match_value = comparison\r\n","\r\n","                # append video match found to results list (using weights)\r\n","                if cur_all_model == \"gray\":\r\n","                    for _ in range(0, self.histogram_comparison_weigths['gray'], 1):\r\n","                        self.results_array.append(video_match)\r\n","                elif cur_all_model == \"rgb\":\r\n","                    for _ in range(0, self.histogram_comparison_weigths['rgb'], 1):\r\n","                        self.results_array.append(video_match)\r\n","\r\n","                print_terminal_table(table_data, method)\r\n","                print(\"{} {} match found: \".format(_get_chosen_model_string(cur_all_model), method) +\r\n","                      \"\\x1b[1;31m\" + video_match + \"\\x1b[0m\" + \"\\n\\n\")\r\n","\r\n","        # use SciPy's statistical distances functions for HSV histograms (compareHist does not work with 3d arrays)\r\n","        elif config.model == \"hsv\" or config.model == \"all\":\r\n","            for m in self.histcmp_3d_methods:\r\n","                if m == \"earths_mover_distance\":\r\n","                    method = \"EARTH'S MOVER DISTANCE\"\r\n","                elif m == \"energy_distance\":\r\n","                    method = \"ENERGY DISTANCE\"\r\n","\r\n","                # CSV file to write data to for each method\r\n","                if config.model == \"all\":\r\n","                    csv_file = open(\"../results/csv/{}-{}-{}.csv\".format(config.model, cur_all_model, method), 'w')\r\n","                else:\r\n","                    csv_file = open(\"../results/csv/{}-{}.csv\".format(config.model, method), 'w')\r\n","                with csv_file:\r\n","\r\n","                    writer = csv.DictWriter(csv_file, fieldnames=csv_field_names)\r\n","                    writer.writeheader()\r\n","\r\n","                    table_data = list()\r\n","                    for i, file in enumerate(get_video_filenames(\"../footage/\")):\r\n","                        dbvideo_hsv_histogram_data = np.loadtxt(\"../histogram_data/{}/hist-hsv.txt\".format(file))\r\n","                        dbvideo_hsv_histogram = dbvideo_hsv_histogram_data.reshape((8, 12, 3))\r\n","                        comparison = 0\r\n","                        for h in range(0, self.bins[0]):  # loop through hue bins\r\n","                            for s in range(0, self.bins[1]):  # loop through saturation bins\r\n","                                query_histogram_slice = query_histogram['hsv'][h][s]\r\n","                                dbvideo_histogram_slice = dbvideo_hsv_histogram[h][s]\r\n","                                if method == \"EARTH'S MOVER DISTANCE\":\r\n","                                    comparison += wasserstein_distance(query_histogram_slice, dbvideo_histogram_slice)\r\n","                                elif method == \"ENERGY DISTANCE\":\r\n","                                    comparison += energy_distance(query_histogram_slice, dbvideo_histogram_slice)\r\n","\r\n","                        # append data to table\r\n","                        table_data.append([file, round(comparison, 5)])\r\n","\r\n","                        # write data to CSV file\r\n","                        writer.writerow({\"video\": file, \"score\": round(comparison, 5)})\r\n","\r\n","                        if i == 0:\r\n","                            video_match = file\r\n","                            video_match_value = comparison\r\n","                        else:\r\n","                            if comparison < video_match_value:\r\n","                                video_match = file\r\n","                                video_match_value = comparison\r\n","\r\n","                # append video match found to results list (using weights)\r\n","                for _ in range(0, self.histogram_comparison_weigths['hsv']):\r\n","                    self.results_array.append(video_match)\r\n","\r\n","                print_terminal_table(table_data, method)\r\n","                print(\"{} {} Match found: \".format(_get_chosen_model_string(cur_all_model), method) +\r\n","                      \"\\x1b[1;31m\" + video_match + \"\\x1b[0m\" + \"\\n\\n\")\r\n","\r\n","    def rgb_histogram_shot_boundary_detection(self, threshold):\r\n","        \"\"\"\r\n","        Compares consecutive frames' RGB histograms using the Intersection metric with a global threshold approach.\r\n","        If the metric is smaller than the specified threshold, then a shot boundary has been detected.\r\n","        :param threshold: integer specifying the global threshold for the algorithm\r\n","        :return: None\r\n","        \"\"\"\r\n","        x_axis = list()\r\n","        y_axis = list()\r\n","        is_under_threshold = True\r\n","\r\n","        ret, frame = self.video_capture.read()  # get initial frame\r\n","\r\n","        frame_counter = 0  # keep track of current frame ID to locate shot boundaries\r\n","        shot_changes_detected = 0  # keep track of the number of shot changes detected\r\n","        while self.video_capture.isOpened():\r\n","            prev_frame = frame[:]  # previous frame\r\n","            ret, frame = self.video_capture.read()  # read capture frame by frame\r\n","\r\n","            if ret:\r\n","                frame_counter += 1\r\n","                cur_rgb_hist = {\r\n","                    'b': list(),\r\n","                    'g': list(),\r\n","                    'r': list()\r\n","                }\r\n","                prev_rgb_hist = {\r\n","                    'b': list(),\r\n","                    'g': list(),\r\n","                    'r': list()\r\n","                }\r\n","                for i, col in enumerate(self.colours):\r\n","                    # calculate RGB histograms\r\n","                    cur_frame_hist = cv2.calcHist([frame], [i], None, [256], [0, 256])\r\n","                    prev_frame_hist = cv2.calcHist([prev_frame], [i], None, [256], [0, 256])\r\n","\r\n","                    # normalise histograms\r\n","                    cur_frame_hist = _normalise_histogram(cur_frame_hist)\r\n","                    prev_frame_hist = _normalise_histogram(prev_frame_hist)\r\n","\r\n","                    # save histograms in dict\r\n","                    cur_rgb_hist[col].append(cur_frame_hist)\r\n","                    prev_rgb_hist[col].append(prev_frame_hist)\r\n","\r\n","                # calculate Intersection between consecutive frames\r\n","                comparison_r = cv2.compareHist(prev_rgb_hist['r'][0], cur_rgb_hist['r'][0], cv2.HISTCMP_INTERSECT)\r\n","                comparison_g = cv2.compareHist(prev_rgb_hist['g'][0], cur_rgb_hist['g'][0], cv2.HISTCMP_INTERSECT)\r\n","                comparison_b = cv2.compareHist(prev_rgb_hist['b'][0], cur_rgb_hist['b'][0], cv2.HISTCMP_INTERSECT)\r\n","                comparison = (comparison_b + comparison_g + comparison_r) / 3\r\n","                # For KL Divergence, use cv2.HISTCMP_KL_DIV\r\n","\r\n","                # append data to lists for plot\r\n","                x_axis.append(frame_counter)\r\n","                y_axis.append(comparison)\r\n","\r\n","                if comparison < threshold and is_under_threshold:\r\n","                    shot_changes_detected += 1\r\n","                    is_under_threshold = False\r\n","                    print(\"Scene Change detected at Frame {}\".format(frame_counter))\r\n","                elif comparison > threshold:\r\n","                    is_under_threshold = True\r\n","\r\n","            else:\r\n","                break\r\n","\r\n","        # Plot results\r\n","        plt.plot(x_axis, y_axis)\r\n","        plt.plot(x_axis, np.full(frame_counter, threshold))\r\n","        plt.title(\"Intersection Between Consecutive Frame RGB Histogram\")\r\n","        plt.xlabel(\"Frame\")\r\n","        plt.ylabel(\"Intersection\")\r\n","        plt.show()\r\n","        print(\"\\n--- Number of shot changes detected: {} ---\".format(shot_changes_detected))\r\n","\r\n","        self.destroy_video_capture()\r\n","\r\n","    def check_video_capture(self):\r\n","        \"\"\"\r\n","        Checks if the VideoCapture object was correctly created.\r\n","        :return: None\r\n","        \"\"\"\r\n","        if not self.video_capture.isOpened():\r\n","            print(\"Error opening video file\")\r\n","\r\n","    def destroy_video_capture(self):\r\n","        \"\"\"\r\n","        Tidying up the OpenCV environment and the video capture.\r\n","        :return: None\r\n","        \"\"\"\r\n","        self.video_capture.release()\r\n","        cv2.destroyAllWindows()\r\n","\r\n","    def get_video_capture(self):\r\n","        \"\"\"\r\n","        Returns the full VideoCapture object.\r\n","        :return: the VideoCapture object\r\n","        \"\"\"\r\n","        return self.video_capture\r\n","\r\n","    def get_current_reference_points(self):\r\n","        \"\"\"\r\n","        Returns the current ROI point locations manually selected for the first frame for future re-use.\r\n","        :return: the ROI pixel locations retrieved from the first frame of the video\r\n","        \"\"\"\r\n","        return self.reference_points\r\n","\r\n","    def get_results_array(self):\r\n","        \"\"\"\r\n","        Returns the array with the resulting video results.\r\n","        :return: array of strings\r\n","        \"\"\"\r\n","        return self.results_array\r\n","\r\n","\r\n","def _normalise_histogram(hist):\r\n","    \"\"\"\r\n","    Normalise a histogram using OpenCV's \"normalize\" function.\r\n","    :param hist: the histogram to normalise\r\n","    :return: the normalised histogram\r\n","    \"\"\"\r\n","    hist = cv2.normalize(hist, hist)\r\n","    return hist\r\n","\r\n","\r\n","def _get_frames_to_process(vc):\r\n","    \"\"\"\r\n","    Returns the IDs of the frames to calculate a histogram for. 1 Frame Per Second.\r\n","    :param vc: the VideoCapture object to process\r\n","    :return: a list of integers representing the frames to process\r\n","    \"\"\"\r\n","    frame_ids = list()\r\n","    total_frames = vc.get(cv2.CAP_PROP_FRAME_COUNT)\r\n","    fps = vc.get(cv2.CAP_PROP_FPS)\r\n","    for i in range(1, int(total_frames) + 1, math.ceil(fps)):\r\n","        frame_ids.append(i)\r\n","    return frame_ids\r\n","\r\n","\r\n","def _get_chosen_model_string(model):\r\n","    \"\"\"\r\n","    Returns the Histogram Model chosen for the matching process.\r\n","    :return: a string representing the chosen histogram model\r\n","    \"\"\"\r\n","    if model == \"gray\":\r\n","        return \"Greyscale\"\r\n","    elif model == \"rgb\":\r\n","        return \"RGB\"\r\n","    elif model == \"hsv\":\r\n","        return \"HSV\"\r\n","    else:\r\n","        if config.model == \"gray\":\r\n","            return \"Greyscale\"\r\n","        elif config.model == \"rgb\":\r\n","            return \"RGB\"\r\n","        elif config.model == \"hsv\":\r\n","            return \"HSV\"\r\n"],"execution_count":null,"outputs":[]}]}