{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"22_05_2021_Work_OPTICAL_FLOW_featureset.ipynb","provenance":[],"authorship_tag":"ABX9TyNtQr9gU+ywOyH8jrksh/vx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lZxbqrFT_r2","executionInfo":{"status":"ok","timestamp":1621658874331,"user_tz":-330,"elapsed":14540,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"14c97982-8542-4738-d0f1-7d0c53ba4eee"},"source":["#OPENCV VERSION FOR USING SIFT\n","!pip install opencv-python==3.4.2.17\n","!pip install opencv-contrib-python==3.4.2.17"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting opencv-python==3.4.2.17\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8f/a5d2fa3a3309c4e4aa28eb989d81a95b57c63406b4d439758a1a0a810c77/opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0MB)\n","\u001b[K     |████████████████████████████████| 25.0MB 146kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: opencv-python\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","Successfully installed opencv-python-3.4.2.17\n","Collecting opencv-contrib-python==3.4.2.17\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/32/8d32d40cd35e61c80cb112ef5e8dbdcfbb06124f36a765df98517a12e753/opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6MB)\n","\u001b[K     |████████████████████████████████| 30.6MB 144kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.19.5)\n","Installing collected packages: opencv-contrib-python\n","  Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","Successfully installed opencv-contrib-python-3.4.2.17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VA0TITHgUWR_","executionInfo":{"status":"ok","timestamp":1621658884800,"user_tz":-330,"elapsed":6617,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"e85a68a9-acef-445a-c4e4-63ba0d3bd4c4"},"source":["#for installing rar file\n","!pip install pyunpack\n","!pip install patool"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyunpack\n","  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n","Collecting easyprocess\n","  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n","Collecting entrypoint2\n","  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n","Installing collected packages: easyprocess, entrypoint2, pyunpack\n","Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\n","Collecting patool\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n","\u001b[K     |████████████████████████████████| 81kB 7.4MB/s \n","\u001b[?25hInstalling collected packages: patool\n","Successfully installed patool-1.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mOqJdJKU-xQ","executionInfo":{"status":"ok","timestamp":1621658889568,"user_tz":-330,"elapsed":1013,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"0d7f6f05-2b4e-406a-93eb-410128480d2a"},"source":["!git clone https://github.com/vkhoi/KTH-Action-Recognition.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'KTH-Action-Recognition'...\n","remote: Enumerating objects: 233, done.\u001b[K\n","remote: Total 233 (delta 0), reused 0 (delta 0), pack-reused 233\u001b[K\n","Receiving objects: 100% (233/233), 709.16 KiB | 18.66 MiB/s, done.\n","Resolving deltas: 100% (148/148), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tA6t389eVKHr","executionInfo":{"status":"ok","timestamp":1621658892908,"user_tz":-330,"elapsed":379,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"261d093a-3836-4e08-8c16-fbb28bd12e3b"},"source":["%cd /content/KTH-Action-Recognition/dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/KTH-Action-Recognition/dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UITkm1M9VNcr"},"source":["from pyunpack import Archive\n","Archive('boxing.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","Archive('handclapping.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","Archive('handwaving.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","Archive('jogging.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","Archive('running.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","Archive('walking.rar').extractall('/content/KTH-Action-Recognition/dataset')\n","\n","!rm *.rar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DO2TTVC7VToz","executionInfo":{"status":"ok","timestamp":1621667784598,"user_tz":-330,"elapsed":3444928,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"29ad91c4-65af-43d4-80db-a8664d0a9e6c"},"source":["#CODE FOR EXTRACTING Spatio temporal SIFT/BEBLID VALUES as features and storing as feature files all categories in one pickle file\n","\n","import cv2\n","import numpy as np\n","import os\n","import pickle\n","import cv2\n","import numpy as np\n","\n","import math\n","from sklearn.cluster import KMeans\n","from sklearn import preprocessing\n","\n","def extract_denseSIFT(img):\n","    DSIFT_STEP_SIZE = 2\n","    sift = cv2.xfeatures2d.SIFT_create()\n","    #sift = cv2.xfeatures2d.BEBLID_create(1)\n","    disft_step_size = DSIFT_STEP_SIZE\n","    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n","            for y in range(0, img.shape[0], disft_step_size)\n","                for x in range(0, img.shape[1], disft_step_size)]\n","\n","    descriptors = sift.compute(img, keypoints)[1]\n","    \n","    #keypoints, descriptors = sift.detectAndCompute(gray, None)\n","    return descriptors\n","\n","\n","CATEGORIES = [\"boxing\", \"handclapping\", \"handwaving\", \"jogging\", \"running\", \"walking\"]\n","\n","if __name__ == \"__main__\":\n","\n","    # Create directory to store extracted pixel features.\n","    os.makedirs(\"data\", exist_ok=True)\n","\n","    \n","    n_processed_files = 0\n","    features = []\n","    L = 3\n","\n","    for category in CATEGORIES:\n","        print(\"Processing category %s\" % category)\n","\n","        # Get all files in current category's folder.\n","        folder_path = os.path.join(\"..\", \"dataset\", category)\n","        filenames = os.listdir(folder_path)\n","\n","        # List to store features. features[i] stores features for the i-th video\n","        # in current category.\n","        #features = []\n","\n","        for filename in filenames:\n","            filepath = os.path.join(\"..\", \"dataset\", category, filename)\n","            path = \"/content/KTH-Action-Recognition/dataset/\" + category + \"/\" + filename\n","            vid = cv2.VideoCapture(filepath)\n","\n","            features_current_file_new = []\n","            count_frame = 0\n","            while vid.isOpened():\n","              ret, frame = vid.read()\n","              count_frame = count_frame + 1\n","              if not ret:\n","                break\n","              if(count_frame < (2**L + 1)):\n","  # Only care about gray scale.\n","                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","                W = frame.shape[1]\n","                H = frame.shape[0]   \n","                h = []\n","                for l in range(L+1):\n","                  w_step = math.floor(W/(2**l))\n","                  h_step = math.floor(H/(2**l))\n","                  x, y = 0, 0\n","                  for i in range(1,2**l + 1):\n","                    x = 0\n","                    for j in range(1, 2**l + 1):                \n","                      desc = extract_denseSIFT(frame[y:y+h_step, x:x+w_step])                \n","                #print(\"type:\",desc is None, \"x:\",x,\"y:\",y, \"desc_size:\",desc is None)\n","                      kmeans = KMeans(n_clusters=60, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","                      predict = kmeans.fit_predict(desc)\n","                      histo = np.bincount(predict, minlength=60).reshape(1,-1).ravel()\n","                      weight = 2**(l-L)\n","                      h.append(weight*histo)\n","                      x = x + w_step\n","                    y = y + h_step\n","            \n","                hist = np.array(h).ravel()\n","    # normalize hist\n","                dev = np.std(hist)\n","                hist -= np.mean(hist)\n","                hist /= dev\n","\n","                features_current_file_new.append(hist)\n","    \n","                features_current_file = np.array(features_current_file_new)\n","\n","\n","            # Store features in current file.\n","    \n","\n","# No of frames\n","#print((features_current_file))  \n"," #     features_current_file = np.array(features_current_file_new)\n","\n","            print(filename)    \n","            print(path)\n","            features.append({\n","                \"filename\": filename,\n","                \"path\" : path,\n","                \"category\": category,\n","                \"features\": features_current_file \n","            })\n","\n","            n_processed_files += 1\n","            if n_processed_files % 30 == 0:\n","                print(\"Done %d files\" % n_processed_files)\n","\n","        # Dump data to file.\n","pickle.dump(features, open(\"data/SIFT_stpm_next24_KTH.p\" , \"wb\"))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing category boxing\n","person04_boxing_d4_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/boxing/person04_boxing_d4_uncomp.avi\n","person03_boxing_d4_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/boxing/person03_boxing_d4_uncomp.avi\n","person04_boxing_d3_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/boxing/person04_boxing_d3_uncomp.avi\n","person04_boxing_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/boxing/person04_boxing_d1_uncomp.avi\n","Processing category handclapping\n","person04_handclapping_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handclapping/person04_handclapping_d2_uncomp.avi\n","person03_handclapping_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handclapping/person03_handclapping_d2_uncomp.avi\n","person03_handclapping_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handclapping/person03_handclapping_d1_uncomp.avi\n","person04_handclapping_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handclapping/person04_handclapping_d1_uncomp.avi\n","Processing category handwaving\n","person03_handwaving_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handwaving/person03_handwaving_d2_uncomp.avi\n","person04_handwaving_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handwaving/person04_handwaving_d1_uncomp.avi\n","person03_handwaving_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handwaving/person03_handwaving_d1_uncomp.avi\n","person04_handwaving_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/handwaving/person04_handwaving_d2_uncomp.avi\n","Processing category jogging\n","person03_jogging_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/jogging/person03_jogging_d2_uncomp.avi\n","person04_jogging_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/jogging/person04_jogging_d1_uncomp.avi\n","person04_jogging_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/jogging/person04_jogging_d2_uncomp.avi\n","person03_jogging_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/jogging/person03_jogging_d1_uncomp.avi\n","Processing category running\n","person04_running_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/running/person04_running_d2_uncomp.avi\n","person03_running_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/running/person03_running_d1_uncomp.avi\n","person03_running_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/running/person03_running_d2_uncomp.avi\n","person04_running_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/running/person04_running_d1_uncomp.avi\n","Processing category walking\n","person03_walking_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/walking/person03_walking_d1_uncomp.avi\n","person04_walking_d1_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/walking/person04_walking_d1_uncomp.avi\n","person04_walking_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/walking/person04_walking_d2_uncomp.avi\n","person03_walking_d2_uncomp.avi\n","/content/KTH-Action-Recognition/dataset/walking/person03_walking_d2_uncomp.avi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41oIESWl8JVr","executionInfo":{"status":"ok","timestamp":1621668003038,"user_tz":-330,"elapsed":458,"user":{"displayName":"Alina Banerjee","photoUrl":"","userId":"10819285316635491372"}},"outputId":"ad443aeb-6232-42fc-a78e-e2cab71d2f8b"},"source":["file = open('/content/KTH-Action-Recognition/dataset/data/SIFT_stpm_next24_KTH.p', 'rb')\n","\n","\n","# dump information to that file\n","data = pickle.load(file)\n","\n","\n","# close the file\n","file.close()\n","\n","\n","\n","print('Showing the pickled data:')\n","\n","\n","cnt = 0\n","for item in data:\n","    cnt = cnt + 1\n","    #print('The data ', cnt, ' is : ', item['path'])\n","    print('The data ', cnt, ' is : ', (item['features']))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Showing the pickled data:\n","The data  1  is :  [[ 5.2589436  10.63721166  4.74321927 ... -0.48769898 -0.48769898\n","  -0.48769898]\n"," [ 3.83811587  4.57085491  3.03210291 ... -0.48504451 -0.48504451\n","  -0.48504451]\n"," [ 3.65877818  3.65877818  4.16713959 ... -0.48073617 -0.48073617\n","  -0.48073617]\n"," ...\n"," [ 3.14656641 11.27040807 14.4619173  ... -0.48014863 -0.48014863\n","  -0.48014863]\n"," [ 2.27523959  8.14815557 14.38359723 ... -0.47995556 -0.47995556\n","  -0.47995556]\n"," [ 3.555155    0.98323651  5.24527286 ... -0.48643119  0.10143589\n","  -0.48643119]]\n","The data  2  is :  [[ 9.13389053  2.84706087  6.43953496 ... -0.4246566  -0.4246566\n","  -0.4246566 ]\n"," [ 5.15470798  7.43498069  0.8475262  ... -0.41929198 -0.41929198\n","  -0.41929198]\n"," [ 2.26503934  9.75533514  7.00249139 ... -0.42378479 -0.42378479\n","  -0.42378479]\n"," ...\n"," [ 1.61136656 15.49083888 16.81269338 ... -0.43750792 -0.43750792\n","  -0.43750792]\n"," [ 1.8901624  10.61489294  7.35144411 ... -0.44087248 -0.44087248\n","  -0.44087248]\n"," [ 1.12111844  4.60437678  2.41121412 ... -0.42699637 -0.42699637\n","   0.0890419 ]]\n","The data  3  is :  [[ 4.59164621  5.17202353  9.48339789 ... -0.54883861 -0.54883861\n","  -0.54883861]\n"," [ 4.52912211  7.61070191  4.36255023 ... -0.55132027 -0.55132027\n","  -0.55132027]\n"," [ 2.1055043   6.58523146  5.17494699 ... -0.54914883 -0.54914883\n","  -0.54914883]\n"," ...\n"," [ 2.77248055  5.59642396  7.34062431 ... -0.54980582 -0.54980582\n","  -0.54980582]\n"," [ 4.81510777  4.81510777  5.96980212 ... -0.54597313 -0.54597313\n","  -0.54597313]\n"," [ 5.72560667  3.49743564  5.39550726 ... -0.54628216 -0.54628216\n","  -0.54628216]]\n","The data  4  is :  [[ 6.27180477  9.15243557  7.39205008 ... -0.52968462 -0.52968462\n","  -0.52968462]\n"," [ 7.77751315  2.93575251  5.84080889 ... -0.53417594 -0.53417594\n","  -0.53417594]\n"," [ 1.87210831  5.95576624  5.95576624 ... -0.53004341 -0.53004341\n","  -0.53004341]\n"," ...\n"," [ 4.983853   10.89604927  5.62300935 ...  0.1102858  -0.52887055\n","  -0.52887055]\n"," [ 2.7805734   4.31723111  6.58177931 ... -0.53537218 -0.53537218\n","  -0.53537218]\n"," [ 2.1892407   5.54741426  9.06550086 ... -0.52928076 -0.52928076\n","  -0.52928076]]\n","The data  5  is :  [[ 2.1129611   5.23670097  6.91871474 ... -0.53020341 -0.53020341\n","  -0.53020341]\n"," [ 9.01464649  4.40318337  6.31137501 ... -0.52631168 -0.52631168\n","   0.1097522 ]\n"," [ 5.70781385  3.14898729  6.1076305  ... -0.52932589 -0.52932589\n","   0.11038075]\n"," ...\n"," [ 6.08683134  6.63745946  3.64833541 ... -0.52070603 -0.52070603\n","  -0.52070603]\n"," [ 5.78582089  6.41659658  4.52426952 ... -0.52193596 -0.52193596\n","  -0.52193596]\n"," [ 3.11069016  3.67803276  7.16313725 ... -0.53651221 -0.53651221\n","  -0.53651221]]\n","The data  6  is :  [[ 8.1993003  11.18428058 11.65559325 ... -0.51998418 -0.51998418\n","  -0.51998418]\n"," [ 6.18809878 11.65404641 12.26992783 ... -0.50961169 -0.50961169\n","  -0.50961169]\n"," [ 7.35705856  8.14491759  6.72677133 ... -0.52153178 -0.52153178\n","  -0.52153178]\n"," ...\n"," [ 2.89877232  4.37218313  4.37218313 ... -0.51333694 -0.51333694\n","  -0.51333694]\n"," [ 6.4676402   7.32088687  8.79467658 ... -0.51346894 -0.51346894\n","  -0.51346894]\n"," [ 3.32228715  3.55746339 11.47506361 ...  0.73534847 -0.51892484\n","  -0.51892484]]\n","The data  7  is :  [[ 4.65331195  8.7081047   6.92399589 ...  0.11194408 -0.53682276\n","  -0.53682276]\n"," [ 7.08747638  7.81747181  2.13972954 ... -0.53692039 -0.53692039\n","  -0.53692039]\n"," [ 3.09042792  7.35804141  5.66710022 ... -0.53301751 -0.53301751\n","  -0.53301751]\n"," ...\n"," [ 5.16296778  5.32588781  6.54778806 ... -0.53923336 -0.53923336\n","  -0.53923336]\n"," [ 3.22529313  8.46695652  5.1909169  ... -0.54215244 -0.54215244\n","  -0.54215244]\n"," [ 4.29732534  7.27596658  5.18286733 ...  0.11112684 -0.5329037\n","  -0.5329037 ]]\n","The data  8  is :  [[ 6.99867858  3.79490327  7.15886735 ... -0.5301934  -0.5301934\n","  -0.5301934 ]\n"," [ 7.42965283  8.37429644  4.51700171 ... -0.52109752 -0.52109752\n","  -0.52109752]\n"," [ 5.75034951  8.80652874  7.94452947 ... -0.5187361  -0.5187361\n","  -0.5187361 ]\n"," ...\n"," [ 5.95684015  7.20466619 10.24624217 ... -0.51625744 -0.51625744\n","  -0.51625744]\n"," [ 3.88381944  4.82763198  4.74898094 ... -0.52063907 -0.52063907\n","  -0.52063907]\n"," [ 4.76683411  6.26682186  8.31943666 ... -0.52259635 -0.52259635\n","  -0.52259635]]\n","The data  9  is :  [[ 1.41364669 11.5658437   4.33624886 ... -0.5091179  -0.5091179\n","  -0.5091179 ]\n"," [ 3.41550533  7.4943738   3.56942489 ... -0.50944358 -0.50944358\n","  -0.50944358]\n"," [ 7.44522087  3.42830958  5.43676523 ... -0.51135341 -0.51135341\n","  -0.51135341]\n"," ...\n"," [ 5.3175831   7.18393675  3.06240577 ... -0.51477205 -0.51477205\n","  -0.51477205]\n"," [ 6.30795464  7.95595665  6.93576493 ... -0.51948224 -0.51948224\n","  -0.51948224]\n"," [ 2.37416999  9.4074992   4.64046496 ... -0.51730979 -0.51730979\n","  -0.51730979]]\n","The data  10  is :  [[ 3.57462175  7.90698177  6.8829694  ... -0.52142772 -0.52142772\n","  -0.52142772]\n"," [ 6.02094542  9.48939578  5.39031809 ... -0.52181321 -0.52181321\n","  -0.52181321]\n"," [ 3.93150612  6.38007046  3.2428474  ... -0.50651674 -0.50651674\n","  -0.50651674]\n"," ...\n"," [ 3.26223367  4.95568521  8.18863817 ... -0.50954478 -0.50954478\n","  -0.50954478]\n"," [ 3.95075668  4.4121105   7.25712571 ... -0.50899689 -0.50899689\n","  -0.50899689]\n"," [ 6.39233515  6.15954911  7.32347932 ... -0.51365077 -0.51365077\n","  -0.51365077]]\n","The data  11  is :  [[ 7.4239478   5.89705443  1.23601152 ...  0.11093219 -0.53197028\n","  -0.53197028]\n"," [ 7.7672045   4.17793776  6.81006671 ... -0.52798974 -0.52798974\n","  -0.52798974]\n"," [ 8.33625264  5.06182196 -0.04948446 ... -0.52866944 -0.52866944\n","  -0.52866944]\n"," ...\n"," [ 2.78448311  4.08033015  7.72489998 ... -0.53612496 -0.53612496\n","  -0.53612496]\n"," [ 4.76764229  6.05227975  5.08880165 ... -0.53148727 -0.53148727\n","  -0.53148727]\n"," [ 2.5763753   5.44992561  6.92775148 ... -0.54347932 -0.54347932\n","  -0.54347932]]\n","The data  12  is :  [[ 8.78911746  4.61475209  6.16990782 ... -0.5418169  -0.5418169\n","  -0.5418169 ]\n"," [ 6.42613602  3.99752518  9.50237641 ... -0.53588171 -0.53588171\n","  -0.53588171]\n"," [ 3.91470063  4.8047659   7.47496172 ...  0.11169447 -0.53562573\n","  -0.53562573]\n"," ...\n"," [ 7.99234955  2.20198029  6.78602262 ... -0.53236075 -0.53236075\n","  -0.53236075]\n"," [ 1.4921002   6.76872934  6.84990825 ... -0.53737255 -0.53737255\n","  -0.53737255]\n"," [ 6.17433975  9.73115507  3.83007511 ... -0.53510733 -0.53510733\n","  -0.53510733]]\n","The data  13  is :  [[ 7.53644004  3.01673898  6.08094309 ... -0.50709574 -0.50709574\n","  -0.50709574]\n"," [ 5.48552567 16.09071457  2.18101029 ... -0.50871153 -0.50871153\n","  -0.50871153]\n"," [ 4.98899731  6.13360592  8.11759417 ... -0.50512401  0.10533392\n","  -0.50512401]\n"," ...\n"," [ 3.4126045   7.03128565  5.06461111 ... -0.52074457 -0.52074457\n","  -0.52074457]\n"," [ 6.40920873  3.97861231  3.82670003 ...  0.10484926 -0.50279985\n","  -0.50279985]\n"," [ 1.65017065  3.34816356  7.74750882 ... -0.51091124 -0.51091124\n","  -0.51091124]]\n","The data  14  is :  [[ 2.37429645  4.79866483 10.13227525 ... -0.5349456  -0.5349456\n","  -0.5349456 ]\n"," [ 2.37429645  4.79866483 10.13227525 ... -0.5349456  -0.5349456\n","  -0.5349456 ]\n"," [ 3.6726204   4.80563586  5.77679196 ... -0.53572271 -0.53572271\n","  -0.53572271]\n"," ...\n"," [ 3.16914048  6.54387345  3.9539621  ... -0.51952114 -0.51952114\n","   0.10833616]\n"," [ 3.07865704  4.48585041  5.73668896 ... -0.51750379 -0.51750379\n","  -0.51750379]\n"," [ 4.35249597  5.45279413  5.76716504 ... -0.52025302 -0.52025302\n","  -0.52025302]]\n","The data  15  is :  [[ 4.91123727  6.31727435  5.9864421  ... -0.54749495 -0.54749495\n","  -0.54749495]\n"," [ 6.45900394  4.26207467  7.19131369 ... -0.5386226  -0.5386226\n","  -0.5386226 ]\n"," [ 1.90683614  5.00600457 10.79655612 ... -0.53987578 -0.53987578\n","  -0.53987578]\n"," ...\n"," [ 8.42547846  8.83695757  8.01399936 ... -0.54476606 -0.54476606\n","   0.11360051]\n"," [ 2.69968976  3.91283747  4.31722004 ... -0.53537081 -0.53537081\n","  -0.53537081]\n"," [ 5.36007944  5.60602838  5.36007944 ... -0.54269518 -0.54269518\n","  -0.54269518]]\n","The data  16  is :  [[ 5.90365485  4.00139489  2.42996276 ... -0.5474876  -0.5474876\n","  -0.5474876 ]\n"," [ 5.90365485  4.00139489  2.42996276 ... -0.5474876  -0.5474876\n","  -0.5474876 ]\n"," [ 3.69475543  9.93865378  2.19621983 ... -0.55109545 -0.55109545\n","  -0.55109545]\n"," ...\n"," [ 4.88551265  3.48684026  4.06276419 ... -0.54462722 -0.54462722\n","  -0.54462722]\n"," [ 3.03018378 10.56908521  5.86740475 ... -0.53660829 -0.53660829\n","  -0.53660829]\n"," [ 5.82267445  9.6036114   5.50089258 ... -0.53251744 -0.53251744\n","  -0.53251744]]\n","The data  17  is :  [[ 3.35549271  7.57211831  8.38300785 ... -0.53677707 -0.53677707\n","  -0.53677707]\n"," [ 4.31155021  7.13851065  4.5538611  ... -0.5346677  -0.5346677\n","  -0.5346677 ]\n"," [ 3.41862805  5.03193452  6.72590632 ... -0.53397281 -0.53397281\n","  -0.53397281]\n"," ...\n"," [ 3.50725407  6.01356789  4.39659123 ... -0.53518757 -0.53518757\n","  -0.53518757]\n"," [ 8.40257936  4.79140456  4.21689948 ... -0.54328548 -0.54328548\n","  -0.54328548]\n"," [ 1.17036     3.85609203  4.75133604 ... -0.53874221 -0.53874221\n","  -0.53874221]]\n","The data  18  is :  [[ 1.48926829  5.78358468  4.24411277 ... -0.53635265  0.11184605\n","  -0.53635265]\n"," [ 6.32517879  8.01984694  3.3393349  ... -0.53419231 -0.53419231\n","  -0.53419231]\n"," [ 4.67313159  5.65042674  8.17510588 ... -0.53910922 -0.53910922\n","   0.11242088]\n"," ...\n"," [ 3.72100638  5.72670653  2.27690227 ... -0.53107794 -0.53107794\n","  -0.53107794]\n"," [ 2.65171777  6.30592941  8.45079276 ... -0.52585757 -0.52585757\n","  -0.52585757]\n"," [ 2.03869495  4.28781144  6.69757912 ...  0.11088081 -0.5317239\n","  -0.5317239 ]]\n","The data  19  is :  [[ 4.36116642  4.51587149  6.06292225 ... -0.51204347 -0.51204347\n","  -0.51204347]\n"," [ 3.36060627  4.60009945  4.90997275 ... -0.51280992 -0.51280992\n","  -0.51280992]\n"," [ 1.90751206  5.89773152  8.87083622 ... -0.51791545  0.10800133\n","  -0.51791545]\n"," ...\n"," [ 3.67336271  5.9511632  16.04941207 ... -0.50260487 -0.50260487\n","  -0.50260487]\n"," [ 2.23054142  5.8746721   3.29341287 ... -0.50255658 -0.50255658\n","  -0.50255658]\n"," [ 2.96677965  3.87081726  7.93898653 ... -0.49869787 -0.49869787\n","  -0.49869787]]\n","The data  20  is :  [[ 6.80493204  8.67398258  6.88280915 ... -0.5155159  -0.5155159\n","   0.10750095]\n"," [ 3.26721373  3.66199173  9.4257506  ... -0.52265511 -0.52265511\n","   0.10898969]\n"," [ 0.90515298  6.71129451  3.84799184 ... -0.52649836 -0.52649836\n","   0.10979113]\n"," ...\n"," [ 3.93871227  8.48518487  4.41728834 ... -0.52799764 -0.52799764\n","  -0.52799764]\n"," [ 3.059907    7.84345426  7.44482532 ... -0.52775345 -0.52775345\n","  -0.52775345]\n"," [ 5.61137698  6.7275867   5.37218919 ...  0.11005765 -0.52777647\n","  -0.52777647]]\n","The data  21  is :  [[ 4.58617152  4.42631999  6.6642413  ... -0.5290772  -0.5290772\n","  -0.5290772 ]\n"," [ 2.74571316  6.2596748   5.94022374 ... -0.52866018 -0.52866018\n","  -0.52866018]\n"," [ 2.58059401  2.42120162  5.84813796 ... -0.52755755 -0.52755755\n","  -0.52755755]\n"," ...\n"," [ 3.92328977  8.47751415  7.0698448  ... -0.54813054 -0.54813054\n","  -0.54813054]\n"," [ 2.28595319  8.568613    7.44095611 ... -0.53318903 -0.53318903\n","  -0.53318903]\n"," [ 6.28553936  3.36129188  5.3107902  ... -0.53770477 -0.53770477\n","  -0.53770477]]\n","The data  22  is :  [[ 2.50410578  4.81826002 12.79810223 ... -0.52823426 -0.52823426\n","  -0.52823426]\n"," [ 2.63362202  8.07753407  5.47392396 ... -0.52226903 -0.52226903\n","  -0.52226903]\n"," [ 4.71950161  3.84523123  6.6270006  ... -0.52612064 -0.52612064\n","  -0.52612064]\n"," ...\n"," [ 2.97339415  7.22338946  4.93493045 ... -0.54102504 -0.54102504\n","  -0.54102504]\n"," [ 4.34360595  6.54061793  2.79756049 ... -0.53864288 -0.53864288\n","  -0.53864288]\n"," [ 2.11536796  3.55873632 11.17651377 ... -0.53080736 -0.53080736\n","  -0.53080736]]\n","The data  23  is :  [[ 5.48091911  6.53837731  5.23689029 ... -0.53845836 -0.53845836\n","  -0.53845836]\n"," [ 4.2131451   6.8371158   6.18112312 ... -0.54280178 -0.54280178\n","  -0.54280178]\n"," [ 5.49815865  9.49649948  8.27251759 ... -0.54015201 -0.54015201\n","  -0.54015201]\n"," ...\n"," [ 5.25844199  4.45415774  5.41929884 ... -0.53240464  0.11102277\n","  -0.53240464]\n"," [ 4.61728746  5.26103174  4.29541531 ... -0.53266684 -0.53266684\n","  -0.53266684]\n"," [ 2.76572565  4.69640216  4.69640216 ... -0.53251339 -0.53251339\n","  -0.53251339]]\n","The data  24  is :  [[ 9.84802507  4.54318828  5.17660163 ... -0.5241185  -0.5241185\n","  -0.5241185 ]\n"," [ 1.35933734  3.70566646  4.56598713 ...  0.10796181 -0.51772595\n","  -0.51772595]\n"," [10.17117685  3.93025262  4.7883797  ... -0.51640589 -0.51640589\n","  -0.51640589]\n"," ...\n"," [ 2.20948138  5.40142939 12.25243976 ... -0.5153523  -0.5153523\n","  -0.5153523 ]\n"," [ 6.03709807  7.22269648  4.93053956 ... -0.5232131  -0.5232131\n","   0.10910605]\n"," [ 2.60425201  5.02279198  3.85253071 ... -0.51644471 -0.51644471\n","  -0.51644471]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QfaAcxX2Wi2n"},"source":["#CODE FOR EXTRACTING Spatio temporal OPTICAL FLOW VALUES as features and storing as feature files all categories in one pickle file\n","\n","import cv2\n","import numpy as np\n","import os\n","import pickle\n","import cv2\n","import numpy as np\n","\n","import math\n","from sklearn.cluster import KMeans\n","from sklearn import preprocessing\n","\n","\n","\n","CATEGORIES = [\"boxing\", \"handclapping\", \"handwaving\", \"jogging\", \"running\", \"walking\"]\n","\n","#TRAIN_PEOPLE_ID = [11, 12, 13, 14, 15, 16, 17, 18]\n","#DEV_PEOPLE_ID = [19, 20, 21, 23, 24, 25, 1, 4]\n","#TEST_PEOPLE_ID = [22, 2, 3, 5, 6, 7, 8, 9, 10]\n","\n","\n","if __name__ == \"__main__\":\n","\n","    # Create directory to store extracted pixel features.\n","    os.makedirs(\"data\", exist_ok=True)\n","\n","    # Setup parameters for optical flow.\n","    farneback_params = dict(winsize = 20, iterations=1, flags=cv2.OPTFLOW_FARNEBACK_GAUSSIAN, levels=1, pyr_scale=0.5, poly_n=5, poly_sigma=1.1, flow=None)\n","\n","    n_processed_files = 0\n","    features = []\n","    L = 3\n","\n","    for category in CATEGORIES:\n","        print(\"Processing category %s\" % category)\n","\n","        # Get all files in current category's folder.\n","        folder_path = os.path.join(\"..\", \"dataset\", category)\n","        filenames = os.listdir(folder_path)\n","\n","        # List to store features. features[i] stores features for the i-th video\n","        # in current category.\n","        #features = []\n","\n","        for filename in filenames:\n","            filepath = os.path.join(\"..\", \"dataset\", category, filename)\n","            path = \"/content/KTH-Action-Recognition/dataset/\" + category + \"/\" + filename\n","            vid = cv2.VideoCapture(filepath)\n","\n","            features_current_file_new = []\n","            count_frame = 0\n","            prev_frame = None\n","            while vid.isOpened():\n","              ret, frame = vid.read()\n","              count_frame = count_frame + 1\n","              if not ret:\n","                break\n","              # Only care about gray scale.\n","              if(count_frame < 2**L + 1):\n","                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","              #print(frame)\n","                if(prev_frame is not None):\n","\n","                  W = frame.shape[1]\n","                  H = frame.shape[0]   \n","                  h = []\n","                  for l in range(L+1):\n","                      w_step = math.floor(W/(2**l))\n","                      h_step = math.floor(H/(2**l))\n","                      x, y = 0, 0\n","                      for i in range(1,2**l + 1):\n","                          x = 0\n","                          for j in range(1, 2**l + 1): \n","                            #desc = extract_denseSIFT(img[y:y+h_step, x:x+w_step])               \n","                            flows = cv2.calcOpticalFlowFarneback(prev_frame[y:y+h_step, x:x+w_step], frame[y:y+h_step, x:x+w_step],**farneback_params)\n","                            feature = []\n","                            #for r in range(w_step):\n","                              #if r % 10 != 0:\n","                                #continue\n","                              #for c in range(h_step):\n","                                #if c % 10 != 0:\n","                                  #continue\n","                                #feature.append(flows[r,c,0])\n","                                #feature.append(flows[r,c,1])\n","                            feature.append(flows)\n","                            feature = np.array(feature)\n","                            feature = feature.reshape(-1, 1)\n","\n","                            kmeans = KMeans(n_clusters=60, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","                            predict = kmeans.fit_predict(feature)\n","\n","                            histo = np.bincount(predict, minlength=60).reshape(1,-1).ravel()\n","                            weight = 2**(l-L)\n","                            h.append(weight*histo)\n","                            x = x + w_step\n","                          y = y + h_step\n","                        \n","                  hist = np.array(h).ravel()\n","                # normalize hist\n","                  dev = np.std(hist)\n","                  hist -= np.mean(hist)\n","                  hist /= dev\n","                  features_current_file_new.append(hist)\n","                #print(flows)\n","                  \n","                  #features_current_file_new.append(feature)\n","                prev_frame = frame\n","            features_current_file_new = np.array(features_current_file_new)\n","            #print(np.array(features_current_file_new))\n","            print((features_current_file_new.shape))\n","\n","\n","            # Store features in current file.\n","    \n","\n","# No of frames\n","#print((features_current_file))  \n"," #     features_current_file = np.array(features_current_file_new)\n","\n","            print(filename)    \n","            print(path)\n","            features.append({\n","                \"filename\": filename,\n","                \"path\" : path,\n","                \"category\": category,\n","                \"features\": features_current_file_new \n","            })\n","\n","            n_processed_files += 1\n","            if n_processed_files % 30 == 0:\n","                print(\"Done %d files\" % n_processed_files)\n","\n","        # Dump data to file.\n","pickle.dump(features, open(\"data/optflow_stpm.p\" , \"wb\"))"],"execution_count":null,"outputs":[]}]}